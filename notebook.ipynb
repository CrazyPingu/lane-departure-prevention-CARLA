{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carla lane departure prevention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import delle librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'manual_control' from 'c:\\\\Users\\\\emanu\\\\Desktop\\\\universita\\\\Smart-vehicular-systems\\\\lane-departure-prevention-CARLA\\\\manual_control.py'>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import carla\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pygame\n",
    "import math\n",
    "from skimage.measure import LineModelND, ransac\n",
    "from queue import Queue\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import manual_control as mc\n",
    "from importlib import reload\n",
    "reload(mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Connessione al server di Carla e creazione degli elementi principali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dichiarazione funzioni base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_spectator_to(transform, distance=5.0, x=0, y=0, z=4, yaw=0, pitch=-30, roll=0):\n",
    "    back_location = transform.location - transform.get_forward_vector() * distance\n",
    "    back_location.x += x\n",
    "    back_location.y += y\n",
    "    back_location.z += z\n",
    "    transform.rotation.yaw += yaw\n",
    "    transform.rotation.pitch = pitch\n",
    "    transform.rotation.roll = roll\n",
    "    spectator_transform = carla.Transform(back_location, transform.rotation)\n",
    "    spectator.set_transform(spectator_transform)\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.mercedes.coupe_2020', rotation=None):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    if rotation:\n",
    "        spawn_point.rotation = rotation\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "def draw_on_screen(world, transform, content='O', color=carla.Color(0, 255, 0), life_time=20):\n",
    "    world.debug.draw_string(transform.location, content, color=color, life_time=life_time)\n",
    "\n",
    "def spawn_camera(attach_to=None, transform=carla.Transform(carla.Location(x=1.2, z=1.2), carla.Rotation(pitch=-10)), fov=90.0, width=800, height=600, sensor_tick=0.0):\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera_bp.set_attribute('fov', str(fov))\n",
    "    camera_bp.set_attribute('sensor_tick', str(sensor_tick))\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera\n",
    "\n",
    "def remove_all(world: carla.World):\n",
    "    '''\n",
    "    Remove all actors and sensors from the world.\n",
    "\n",
    "    Args:\n",
    "        world: the world to remove actors and sensors from\n",
    "    '''\n",
    "    for a in world.get_actors().filter('vehicle.*'):\n",
    "        a.destroy()\n",
    "    for a in world.get_actors().filter('sensor.*'):\n",
    "        a.destroy()\n",
    "\n",
    "def proportional_spaced_array(pts: list, min_value: float, max_value: float):\n",
    "    '''\n",
    "    Generate an array of values that are proportional to the input array in increasing or decreasing.\n",
    "\n",
    "    Args:\n",
    "        pts: the input array\n",
    "        min_value: the minimum value of the output array\n",
    "        max_value: the maximum value of the output array\n",
    "\n",
    "    Returns:\n",
    "        a list of values that are proportional to the input array in increasing or decreasing\n",
    "    '''\n",
    "    delta_dist = max_value - min_value\n",
    "    pts_max = pts[0]\n",
    "    pts_min = pts[len(pts) - 1]\n",
    "    delta_pts = pts_max - pts_min\n",
    "\n",
    "    buffer = []\n",
    "    for i in range(0, len(pts)):\n",
    "        buffer.append(delta_dist * (pts_max - pts[i]) / delta_pts + min_value)\n",
    "\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp immagine\n",
    "\n",
    "*ImageWarp* è una classe che fornisce i metodi per deformare un'immagine e per riportarla come originale.\n",
    "\n",
    "Metodi:\n",
    "\n",
    "- **img_warp**: deforma o riporta allo stato originale l'immagine.\n",
    "\n",
    "- **pts_unwarp**: trasforma i punti individuati sull'immagine deformata alla forma che si adatta all'immagine originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageWarp():\n",
    "\n",
    "    def __init__(self, img_height=240, img_width=320, offset=150, src=[[50, 240], [200, 240], [0, 0], [320, 0]], dst=[[135, 240], [150, 240], [0, 0], [320, 0]]):\n",
    "        '''\n",
    "        Initialize the ImageWarp object.\n",
    "\n",
    "        Args:\n",
    "            img_height: the height of the image\n",
    "            img_width: the width of the image\n",
    "            offset: the height offset of the image\n",
    "            src: the source points of the image\n",
    "            dst: the destination points of the image\n",
    "        '''\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.warp_offset = offset\n",
    "        self.src = np.float32(src)\n",
    "        self.dst = np.float32(dst)\n",
    "        self.warp_mat = cv2.getPerspectiveTransform(self.src, self.dst)\n",
    "        self.warp_mat_inv = cv2.getPerspectiveTransform(self.dst,self.src)\n",
    "\n",
    "    def img_warp(self, img, inv=False, offset=False):\n",
    "        '''\n",
    "        Warps an image based on the input parameters\n",
    "\n",
    "        Args:\n",
    "            img ([type]): RGB / Gray image\n",
    "            inv: invers transformation. Defaults to False.\n",
    "            offset: use offset for warping the image. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            [type]: warped image\n",
    "        '''\n",
    "        ret = []\n",
    "        temp_img = None\n",
    "\n",
    "        if offset == True:\n",
    "            temp_img = img[self.warp_offset:self.warp_offset+self.img_height, 0:self.img_width]\n",
    "        else:\n",
    "            temp_img = img\n",
    "\n",
    "        if inv == False:\n",
    "            ret = cv2.warpPerspective(temp_img, self.warp_mat, (self.img_width, self.img_height))\n",
    "        else:\n",
    "            ret = cv2.warpPerspective(temp_img, self.warp_mat_inv, (self.img_width, self.img_height))\n",
    "        return ret\n",
    "\n",
    "    def pts_unwarp(self, pts):\n",
    "        '''\n",
    "        Backprojects points from warped image to un-warped image\n",
    "\n",
    "        Args:\n",
    "            pts: points to backproject\n",
    "\n",
    "        Returns:\n",
    "            the backprojected points\n",
    "        '''\n",
    "        return cv2.perspectiveTransform(pts, self.warp_mat_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector dei punti appartenenti alle linee stradali\n",
    "\n",
    "*Detector* è una classe che fornisce i metodi per individuare i punti appartenenti alle linee stradali che definiscono la carreggiata.\n",
    "\n",
    "Metodi:\n",
    "\n",
    "- **img_filter**: rileva i bordi nell'immagine (con *Canny* vengono rilevati tutti i bordi, mentre con *Sobel* solo quelli verticali), li dilata per migliorarne la visibilità, applica una soglia per binarizzare l'immagine e combina i risultati per ottenere un'immagine finale con bordi più definiti e continui.\n",
    "\n",
    "- **get_lane_detections**: scansiona verticalmente l'immagine per rilevare i bordi delle corsie, calcola l'istogramma delle rilevazioni, trova i picchi, applica un offset per centrare la finestra di rilevamento, memorizza le coordinate dei picchi e filtra i punti anomali utilizzando RANSAC.\n",
    "\n",
    "- **draw_detections**: disegna i punti rilevati appartenenti alle linee stradali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector():\n",
    "\n",
    "    def __init__(self, scan_range={'start': 0, 'stop': 240, 'steps': 20}, scan_window={'height': 15, 'max_adjust': 10}):\n",
    "        '''\n",
    "        Initialize the Detector object.\n",
    "\n",
    "        Args:\n",
    "            scan_range: the vertical range of the scan\n",
    "            scan_window: the window of the scan for each step\n",
    "        '''\n",
    "        self.scan_range = scan_range\n",
    "        self.scan_window = scan_window\n",
    "        self.model = LineModelND()\n",
    "\n",
    "    def img_filter(self, img):\n",
    "        '''\n",
    "        Filters an RGB image to get the lane boundaries.\n",
    "\n",
    "        Args:\n",
    "            img ([type]): RGB image\n",
    "\n",
    "        Returns:\n",
    "            [type]: RGB image\n",
    "        '''\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        cimg = cv2.Canny(img, 50, 250)\n",
    "        cimg = cv2.morphologyEx(cimg, cv2.MORPH_DILATE, (1, 1), iterations=5)\n",
    "\n",
    "        simg = cv2.Sobel(img, cv2.CV_8U, 1, 0, ksize=1)\n",
    "        simg = cv2.morphologyEx(simg, cv2.MORPH_DILATE, (1, 1), iterations=5)\n",
    "        _, simg= cv2.threshold(simg, 50, 255, cv2.THRESH_OTSU)\n",
    "        simg = cv2.morphologyEx(simg, cv2.MORPH_CLOSE, (3,3))\n",
    "\n",
    "        img = cv2.bitwise_and(cimg, cimg, mask=simg)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def get_lane_detections(self, img, start={'x': 105, 'y': 230}, stop={'x': 135, 'y': 230}, use_RANSAC=True):\n",
    "        '''\n",
    "        Parses the input image, with virtual sensors, detects the peaks and save the points.\n",
    "\n",
    "        Args:\n",
    "            img ([type]): 1 channel gray image\n",
    "            start: detection area start. Defaults to {'x': 105, 'y': 230}.\n",
    "            stop: detection area start. Defaults to {'x': 135, 'y': 230}.\n",
    "            use_RANSAC: Use RANSAC. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            [type]: detections coordinates\n",
    "        '''\n",
    "        adjust = 0\n",
    "        minx = min(start['x'], stop['x'])\n",
    "        maxx = max(start['x'], stop['x']) + adjust\n",
    "        detections = []\n",
    "        for i in range (self.scan_range['start'], self.scan_range['stop'], self.scan_range['steps']):\n",
    "            # detections y coordinate\n",
    "            y = start['y'] - i\n",
    "\n",
    "            # get detections from a line\n",
    "            det_line = img[y:y + self.scan_window['height'], minx:maxx]\n",
    "\n",
    "            # scan an image segment, sum detection\n",
    "            hist = np.sum(det_line, axis=0)\n",
    "\n",
    "            # get peak location\n",
    "            peak = np.argmax(hist)\n",
    "\n",
    "            # define threshold = average, find peaks\n",
    "            if hist[peak] > np.average(hist):\n",
    "\n",
    "                x1 = minx + peak\n",
    "                y1 = y\n",
    "                det_mid_x = minx + len(hist) // 2\n",
    "\n",
    "                adjust = x1 - det_mid_x\n",
    "\n",
    "                # apply adjust only if in defined range\n",
    "                if np.abs(adjust) >= self.scan_window['max_adjust']:\n",
    "                    sign = np.sign(adjust)\n",
    "                    adjust = sign * self.scan_window['max_adjust']\n",
    "\n",
    "                minx += adjust\n",
    "                maxx += adjust\n",
    "\n",
    "                detections.append([x1, y1])\n",
    "\n",
    "        if use_RANSAC == True:\n",
    "            _, inliers = self.filter_outliers(detections)\n",
    "            if inliers is not None:\n",
    "                detections = np.array(detections)[inliers]\n",
    "\n",
    "        return detections\n",
    "\n",
    "    def filter_outliers(self, data):\n",
    "        '''\n",
    "        Apply RUNSAC.\n",
    "\n",
    "        Args:\n",
    "            data ([type]): data points\n",
    "\n",
    "        Returns:\n",
    "            [type]: filtered list\n",
    "        '''\n",
    "        model_robust = None\n",
    "        inliers = None\n",
    "        data = np.array(data)\n",
    "        self.model.estimate(data)\n",
    "\n",
    "        try:\n",
    "            model_robust, inliers = ransac(data, LineModelND, min_samples=2, residual_threshold=1, max_trials=200)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return model_robust, inliers\n",
    "\n",
    "    def draw_detections(self, img, data):\n",
    "        '''\n",
    "        Visualize detections.\n",
    "\n",
    "        Args:\n",
    "            img ([type]): RGB image\n",
    "            data ([type]): points detected\n",
    "\n",
    "        Returns:\n",
    "            [type]: RGB image with detections\n",
    "        '''\n",
    "        limg = img.copy()\n",
    "        for v in data:\n",
    "            cv2.circle(limg, (v[0], v[1]), 2, [255], -1)\n",
    "\n",
    "        return limg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolatore dei punti individuati\n",
    "\n",
    "*Interpolator* è una classe che permette di ottenere le linee che meglio approssimano quelle della strada, partendo dai punti rilevati.\n",
    "\n",
    "Metodi:\n",
    "\n",
    "- **interpolate**: esegue l'interpolazione polinomiale sui punti di una corsia rilevata, seleziona il miglior grado del polinomio se richiesto, calcola i valori interpolati e restituisce le coordinate interpolate.\n",
    "\n",
    "- **echidistant_lane**: genera l'altra linea della corsia data la linea identificata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interpolator():\n",
    "\n",
    "    def __init__(self, max_poly_degree=3):\n",
    "        '''\n",
    "        Initialize the Interpolator object.\n",
    "\n",
    "        Args:\n",
    "            max_poly_degree: the maximum polynomial degree\n",
    "        '''\n",
    "        self.max_poly_degree = max_poly_degree\n",
    "\n",
    "    def interpolate(self, pts=dict(), ip_params={'start': 0, 'stop': 240, 'steps': 20}, key='mid', equ_selector=False):\n",
    "        '''\n",
    "        Takes detected points, find the corresponding polynom that fits the data.\n",
    "\n",
    "        Args:\n",
    "            pts ([type], optional): detected points. Defaults to dict().\n",
    "            ip_params (dict, optional): interpolation info. Defaults to {'start': 0, 'stop': 240, 'steps': 20}.\n",
    "            key (str, optional): Name of the line. Defaults to 'mid'.\n",
    "            equ_selector (bool, optional): search the best fitting equation (line / curve, etc.). Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            [type]: interpolated points\n",
    "        '''\n",
    "        data = np.array(pts[0][key])\n",
    "\n",
    "        x_coord = data[:,0]\n",
    "        y_coord = data[:,1]\n",
    "\n",
    "        min_mse_pos = self.max_poly_degree\n",
    "\n",
    "        # polynomial degree selector\n",
    "        if equ_selector == True:\n",
    "            # find the best fit\n",
    "            best_poly = []\n",
    "            best_fit = []\n",
    "            for i in range(0, self.max_poly_degree + 1):\n",
    "                pfit = np.polyfit(y_coord, x_coord,i)\n",
    "                polynom = np.poly1d(pfit)\n",
    "                test_y = polynom(x_coord)\n",
    "                difference = y_coord - test_y\n",
    "                st_d = np.std(difference)\n",
    "                best_poly.append(st_d)\n",
    "                best_fit.append((pfit, polynom))\n",
    "\n",
    "            # select best polynom\n",
    "            min_mse_pos = np.argmin(np.array(best_poly))\n",
    "\n",
    "        # order start from 1, position from 0\n",
    "        pfit = np.polyfit(y_coord, x_coord, min_mse_pos)\n",
    "        polynom = np.poly1d(pfit)\n",
    "\n",
    "        y_ipp = np.float32(np.linspace(ip_params['start'],ip_params['stop'],ip_params['steps']))\n",
    "        x_ipp = polynom(y_ipp)\n",
    "\n",
    "        ply_coords = np.column_stack((x_ipp,y_ipp))\n",
    "        return {key:ply_coords}\n",
    "\n",
    "    def echidistant_lane(self, warper: ImageWarp, lane_pts, init_dist=115, final_dist=250, lane_side=1):\n",
    "        '''\n",
    "        Create echidistant lane based on the input lane points, considering the deformation generated by the prospective of the camera.\n",
    "\n",
    "        Args:\n",
    "            warper: ImageWarp object\n",
    "            lane_pts: points belonging to the lane detected\n",
    "            init_dist: initial distance (width of the roadway at the most distant point from the camera)\n",
    "            final_dist: final distance (width of the roadway at the closest point to the camera)\n",
    "            lane_side: if it is equal to 1, the lane detected is the right one, if it is equal to -1, the lane detected is the left one\n",
    "\n",
    "        Returns:\n",
    "            echidistant generated lane points\n",
    "        '''\n",
    "        buffer = []\n",
    "        dist = init_dist\n",
    "        dist = proportional_spaced_array(lane_pts[0][:, 1], init_dist, final_dist)\n",
    "        # create the lane points echidistant to the passed points\n",
    "        for i in range(0, len(lane_pts[0])):\n",
    "            x = lane_pts[0][i][0]\n",
    "            y = lane_pts[0][i][1]\n",
    "\n",
    "            nx = x\n",
    "            nx = nx - dist[i] * lane_side\n",
    "\n",
    "            norm_pts = np.float32(np.column_stack((nx, y)))\n",
    "            buffer.append(norm_pts)\n",
    "\n",
    "        buffer = np.array(buffer, dtype=np.float32)\n",
    "        buffer = cv2.perspectiveTransform(buffer, warper.warp_mat)\n",
    "\n",
    "        return np.array(buffer, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settaggi per il processing\n",
    "\n",
    "- *src* e *dst* rappresentano l'associazione dei punti dell'immagine di partenza con quelli dell'immagine deformata (es: il punto con coordinate (70, 240) corrisponderà al punto (155, 270) nell'immagine trasformata, in modo analogo gli altri punti)\n",
    "- *scan_range* indica il range verticale nel quale verranno valutati i punti delle linee e il salto da fare per ogni valutazione\n",
    "- *scan_window* rappresenta la finestra nella quale viene cercato un punto appartenente ad una linea\n",
    "- *offset* indica l'offset verticale\n",
    "- *image_width* contiene la larghezza dell'immagine\n",
    "- *lanes* rappresenta le aree nelle quali vengono valutate le linee della carreggiata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src = [[70, 240], [430, 240], [0, 0], [500, 0]]\n",
    "dst = [[155, 270], [165, 270], [0, 0], [320, 0]]\n",
    "\n",
    "scan_range = {'start': 0, 'stop': 240, 'steps': 10}\n",
    "scan_window = {'height': 8, 'max_adjust': 8}\n",
    "offset = 150\n",
    "image_width = 500\n",
    "\n",
    "lanes = [\n",
    "    {'label': 'mid', 'detections': {'start': {'x': 120, 'y': 230}, 'stop': {'x': 160, 'y': 230}}},\n",
    "    {'label': 'right', 'detections': {'start': {'x': 160, 'y': 230}, 'stop': {'x': 200, 'y': 230}}}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Istanziamento degli oggetti per il processing dell'immagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "warper = ImageWarp(img_width=image_width, offset=offset, src=src, dst=dst)\n",
    "detector = Detector(scan_range=scan_range, scan_window=scan_window)\n",
    "interpolator = Interpolator(max_poly_degree=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzione di processing dell'immagine\n",
    "\n",
    "Questa funzione rileva le linee di corsia in un'immagine, le interpola per ottenere curve lisce, le trasforma alla prospettiva originale e salva i risultati in una coda, per la visualizzazione.\n",
    "\n",
    "La linea rilevata viene mostrata in **blu**, mentre la linea generata a partire da quella rilevata viene disegnata in **verde**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, res):\n",
    "    '''\n",
    "    Process the input image, detect lanes, interpolate and draw the echidistant lane.\n",
    "\n",
    "    Args:\n",
    "        image: the input image\n",
    "        res: the queue to put the result\n",
    "    '''\n",
    "    try:\n",
    "        img = image.copy()\n",
    "        f_img = detector.img_filter(img)\n",
    "        f_w_img = warper.img_warp(f_img, offset=True)\n",
    "\n",
    "        color = [1, 1, 1]\n",
    "\n",
    "        # img_detected_points = f_w_img.copy()\n",
    "        debug = f_w_img.copy()\n",
    "\n",
    "        # detect lanes points\n",
    "        detected_points = {}\n",
    "        for i, lane in enumerate(lanes):\n",
    "            detected_points[lane['label']] = detector.get_lane_detections(f_w_img, start=lane['detections']['start'], stop=lane['detections']['stop'], use_RANSAC=True)\n",
    "\n",
    "            # draw detection area\n",
    "            start_x = lane['detections']['start']['x']\n",
    "            start_y = lane['detections']['start']['y']\n",
    "            stop_x = lane['detections']['stop']['x']\n",
    "            stop_y = lane['detections']['stop']['y']\n",
    "            cv2.rectangle(debug, (start_x, start_y), (stop_x, stop_y), (255, 255, 255), 2)\n",
    "\n",
    "        # select the best lane (the one with the most detected points)\n",
    "        lane = None\n",
    "        if detected_points['mid'].shape[0] > detected_points['right'].shape[0]:\n",
    "            lane = lanes[0]\n",
    "        else:\n",
    "            lane = lanes[1]\n",
    "\n",
    "        # img_detected_points = detector.draw_detections(img_detected_points, detected_points[lane['label']])\n",
    "\n",
    "        # interpolate the lane points\n",
    "        interpolated_points = interpolator.interpolate([detected_points], key=lane['label'], equ_selector=False)\n",
    "\n",
    "        pts = np.array([interpolated_points[lane['label']]])\n",
    "        cv2.polylines(debug, [np.int32(pts)], False, [155], 2)\n",
    "\n",
    "        # unwarp the lane points\n",
    "        unwarped_pts = np.int32(warper.pts_unwarp(pts))\n",
    "        unwarped_pts_offset = np.add(unwarped_pts, [0, offset])\n",
    "\n",
    "        color[0] = 255\n",
    "        cv2.polylines(img, [unwarped_pts_offset], False, color, 2)\n",
    "\n",
    "        # estimate the echidistant lane\n",
    "        ed_pts = np.float32(interpolator.echidistant_lane(warper=warper, lane_pts=unwarped_pts, lane_side=1 if lane['label'] == 'right' else -1))\n",
    "        cv2.polylines(debug, [np.int32(ed_pts)], False, [155], 2)\n",
    "\n",
    "        # unwarp the echidistant lane points\n",
    "        ed_unwarped_pts = np.int32(warper.pts_unwarp(ed_pts))\n",
    "        ed_unwarped_pts_offset = np.add(ed_unwarped_pts, [0, offset])\n",
    "\n",
    "        color[0] = 1\n",
    "        color[1] = 255\n",
    "        cv2.polylines(img, [ed_unwarped_pts_offset], False, color, 2)\n",
    "\n",
    "        # draw the separation for the lanes\n",
    "        middle = lanes[0]['detections']['stop']['x']\n",
    "        cv2.rectangle(debug, (middle, lane['detections']['start']['y'] - 10), (middle, lane['detections']['start']['y'] + 10), (255, 255, 255), 2)\n",
    "        concat_img = cv2.hconcat([img, cv2.cvtColor(debug[:, :dst[3][0]], cv2.COLOR_GRAY2RGB)])\n",
    "\n",
    "        ed_pts = ed_pts.reshape(20, 2)\n",
    "        detection_index = len(pts[0]) - 2\n",
    "        left_lane = pts[0][detection_index] if lane['label'] == 'mid' else ed_pts[detection_index]\n",
    "        right_lane = ed_pts[detection_index] if lane['label'] == 'mid' else pts[0][detection_index]\n",
    "        top_left = pts[0][0] if lane['label'] == 'mid' else ed_pts[0]\n",
    "        top_right = ed_pts[0] if lane['label'] == 'mid' else pts[0][0]\n",
    "\n",
    "        res.put({'img': concat_img, 'left_lane': left_lane[0], 'right_lane': right_lane[0], 'far_left': top_left[0], 'far_right': top_right[0]})\n",
    "\n",
    "    except Exception as e:\n",
    "        concat_img = cv2.hconcat([image, cv2.cvtColor(f_w_img[:, :dst[3][0]], cv2.COLOR_GRAY2RGB)])\n",
    "\n",
    "        res.put({'img': concat_img, 'left_lane': None, 'right_lane': None, 'far_left': None, 'far_right': None})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzioni e oggetti provenienti da *manual_control.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'oggetto **GameLoop** e la funzione **setup** sono stati presi da *manual_control.py* e modificati secondo le esigenze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variabili e funzioni utili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *steer_correction_time* rappresenta la durata della correzione dello sterzo per non oltrepassare la linea (dipende dal frame rate massimo impostato).\n",
    "- *last_left_lane* e *last_right_lane* contengono rispettivamente il precedente valore della liena di sinistra e di destra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "steer_correction_time = 3\n",
    "\n",
    "last_left_lane = None\n",
    "last_right_lane = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **detections_processing**: controlla eventuali rilevazioni incorrette/inaspettate della corsia e le corregge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detection_processing(left_lane: int, right_lane: int, threshold=5):\n",
    "#     '''\n",
    "#     Checks and corrects the lane detection if necessary.\n",
    "\n",
    "#     Args:\n",
    "#         left_lane: the left lane detected\n",
    "#         right_lane: the right lane detected\n",
    "#         threshold: the max movement of the line position to consider the detection valid\n",
    "\n",
    "#     Returns:\n",
    "#         the left and right lane corrected if necessary, if there was a correction\n",
    "#     '''\n",
    "#     global last_left_lane, last_right_lane\n",
    "#     if last_left_lane is not None and last_right_lane is not None:\n",
    "#         # if abs(last_left_lane - left_lane) < abs(last_left_lane - right_lane):\n",
    "#         #     last_left_lane = left_lane\n",
    "#         #     last_right_lane = right_lane\n",
    "#         #     return left_lane, right_lane, False\n",
    "#         # elif abs(last_left_lane - left_lane) > abs(last_left_lane - right_lane):\n",
    "#         #     last_left_lane = left_lane\n",
    "#         #     last_right_lane = right_lane\n",
    "#         #     return right_lane, left_lane, True\n",
    "#         if (left_lane > last_left_lane - threshold and left_lane < last_left_lane + threshold) and (right_lane > last_right_lane - threshold and right_lane < last_right_lane + threshold):\n",
    "#             last_left_lane = left_lane\n",
    "#             last_right_lane = right_lane\n",
    "#             return left_lane, right_lane, False\n",
    "#         elif (left_lane > last_left_lane + threshold) and (right_lane > last_right_lane + threshold):\n",
    "#             last_left_lane = left_lane + threshold\n",
    "#             last_right_lane = right_lane + threshold\n",
    "#             return last_left_lane, last_right_lane, True\n",
    "#         elif (left_lane < last_left_lane - threshold) and (right_lane < last_right_lane - threshold):\n",
    "#             last_left_lane = left_lane - threshold\n",
    "#             last_right_lane = right_lane - threshold\n",
    "#             return last_left_lane, last_right_lane, True\n",
    "#     else:\n",
    "#         last_left_lane = left_lane\n",
    "#         last_right_lane = right_lane\n",
    "#         return left_lane, right_lane, False\n",
    "\n",
    "class LineDetectionCorrector:\n",
    "    def __init__(self, max_history=5, threshold=10):\n",
    "        self.max_history = max_history\n",
    "        self.threshold = threshold\n",
    "        self.left_lane_history = []\n",
    "        self.right_lane_history = []\n",
    "\n",
    "    def add_to_history(self, history, value):\n",
    "        if len(history) >= self.max_history:\n",
    "            history.pop(0)\n",
    "        elif len(history) > 1:\n",
    "            if value > history[len(history) - 1] - self.threshold and value < history[len(history) - 1] + self.threshold:\n",
    "                history.append(value)\n",
    "            else:\n",
    "                movement = history[len(history) - 1] - history[len(history) - 2]\n",
    "                history.append(history[len(history) - 1] + movement)\n",
    "        else:\n",
    "            history.append(value)\n",
    "\n",
    "    def is_too_far(self, history, value):\n",
    "        if not history:\n",
    "            return False\n",
    "        avg = np.mean(history)\n",
    "        return abs(value - avg) > self.threshold\n",
    "\n",
    "    def detection_processing(self, left_lane, right_lane):\n",
    "        correction = False\n",
    "\n",
    "        if left_lane is not None:\n",
    "            if self.is_too_far(self.left_lane_history, left_lane):\n",
    "                correction = True\n",
    "            self.add_to_history(self.left_lane_history, left_lane)\n",
    "\n",
    "        if right_lane is not None:\n",
    "            if self.is_too_far(self.right_lane_history, right_lane):\n",
    "                correction = True\n",
    "            self.add_to_history(self.right_lane_history, right_lane)\n",
    "\n",
    "        return left_lane, right_lane, correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game loop e setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameLoop(object):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        pygame.init()\n",
    "        pygame.font.init()\n",
    "        self.world = None\n",
    "        self.original_settings = None\n",
    "        # steer_cache is used to apply small steering corrections.\n",
    "        self.steer_cache = None\n",
    "        self.fps = args.maxfps\n",
    "        # self.corrector = LineDetectionCorrector()\n",
    "\n",
    "        try:\n",
    "            self.sim_world = client.get_world()\n",
    "            if args.sync:\n",
    "                self.original_settings = self.sim_world.get_settings()\n",
    "                settings = self.sim_world.get_settings()\n",
    "                if not settings.synchronous_mode:\n",
    "                    settings.synchronous_mode = True\n",
    "                    settings.fixed_delta_seconds = 0.05\n",
    "                self.sim_world.apply_settings(settings)\n",
    "\n",
    "                traffic_manager = client.get_trafficmanager()\n",
    "                traffic_manager.set_synchronous_mode(True)\n",
    "\n",
    "            if args.autopilot and not self.sim_world.get_settings().synchronous_mode:\n",
    "                print(\"WARNING: You are currently in asynchronous mode and could \"\n",
    "                    \"experience some issues with the traffic simulation\")\n",
    "\n",
    "            self.display = pygame.display.set_mode(\n",
    "                (args.width, args.height),\n",
    "                pygame.HWSURFACE | pygame.DOUBLEBUF)\n",
    "            self.display.fill((0,0,0))\n",
    "            pygame.display.flip()\n",
    "\n",
    "            hud = mc.HUD(args.width, args.height)\n",
    "            self.world = mc.World(self.sim_world, hud, args)\n",
    "            self.controller = mc.KeyboardControl()\n",
    "\n",
    "            if args.sync:\n",
    "                self.sim_world.tick()\n",
    "            else:\n",
    "                self.sim_world.wait_for_tick()\n",
    "        except Exception:\n",
    "            mc.logging.exception('Error creating the world')\n",
    "\n",
    "    def get_speed(self, vehicle: carla.Vehicle):\n",
    "        velocity = vehicle.get_velocity()\n",
    "        speed = math.sqrt(velocity.x**2 + velocity.y**2 + velocity.z**2)\n",
    "        return speed\n",
    "\n",
    "    def render(self, clock):\n",
    "        self.world.tick(clock)\n",
    "        self.world.render(self.display)\n",
    "        pygame.display.flip()\n",
    "\n",
    "    def get_blinkers_state(self):\n",
    "        light_state = self.world.player.get_light_state()\n",
    "        left_blinker = light_state & carla.VehicleLightState.LeftBlinker\n",
    "        right_blinker = light_state & carla.VehicleLightState.RightBlinker\n",
    "        return left_blinker, right_blinker\n",
    "\n",
    "    def start(self, processed_output, autopilot=False, detection_center=100, threshold=20):\n",
    "        self.world.player.set_autopilot(autopilot)\n",
    "        try:\n",
    "            clock = pygame.time.Clock()\n",
    "            while True:\n",
    "                if self.args.sync:\n",
    "                    self.sim_world.tick()\n",
    "                clock.tick_busy_loop(self.fps)\n",
    "\n",
    "                if self.controller.parse_events(self.world, clock):\n",
    "                    return\n",
    "                self.render(clock)\n",
    "\n",
    "                # Show processed camera output\n",
    "                try:\n",
    "                    output = processed_output.get_nowait()\n",
    "                    # cv2.imshow('Processed image', output['img'])\n",
    "\n",
    "                    left_blinker, right_blinker = self.get_blinkers_state()\n",
    "                    if not left_blinker:\n",
    "                        if output['left_lane'] is not None:\n",
    "                            left = output['left_lane']\n",
    "                            far_left = output['far_left']\n",
    "                            # left, _, correction = detection_processing(output['left_lane'], output['right_lane'])\n",
    "                            # left, _, correction = self.corrector.detection_processing(output['left_lane'], output['right_lane'])\n",
    "                            # print(correction)\n",
    "                            if (left > detection_center - threshold or far_left > detection_center + threshold // 2) and self.get_speed(self.world.player) > 0:\n",
    "                                print(f'\\033[94mLine left:\\033[0m', left, detection_center - threshold)\n",
    "                                self.steer_cache = 1\n",
    "                                extra = 0\n",
    "                                if far_left > detection_center + threshold // 2:\n",
    "                                    extra = 3\n",
    "                                for _ in range(steer_correction_time + extra):\n",
    "                                    self.world.player.apply_control(carla.VehicleControl(steer=self.steer_cache, throttle=0.5))\n",
    "                                    self.render(clock)\n",
    "\n",
    "                    if not right_blinker:\n",
    "                        if output['right_lane'] is not None:\n",
    "                            right = output['right_lane']\n",
    "                            far_right = output['far_right']\n",
    "                            # _, right, correction = detection_processing(output['left_lane'], output['right_lane'])\n",
    "                            # _, right, correction = self.corrector.detection_processing(output['left_lane'], output['right_lane'])\n",
    "                            # print(correction)\n",
    "                            if (right < detection_center + threshold or far_right < detection_center - threshold // 2) and self.get_speed(self.world.player) > 0:\n",
    "                                print('\\033[92mLine right:\\033[0m', right, detection_center + threshold)\n",
    "                                self.steer_cache = -1\n",
    "                                extra = 0\n",
    "                                if far_right < detection_center - threshold // 2:\n",
    "                                    extra = 3\n",
    "                                for _ in range(steer_correction_time + extra):\n",
    "                                    self.world.player.apply_control(carla.VehicleControl(steer=self.steer_cache, throttle=0.5))\n",
    "                                    self.render(clock)\n",
    "\n",
    "                    cv2.imshow('Processed image', output['img'])\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                cv2.waitKey(1)\n",
    "        finally:\n",
    "\n",
    "            if self.original_settings:\n",
    "                self.sim_world.apply_settings(self.original_settings)\n",
    "\n",
    "            if self.world is not None:\n",
    "                self.world.destroy()\n",
    "\n",
    "            pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    argparser = mc.argparse.ArgumentParser(description='CARLA Manual Control Client')\n",
    "    argparser.add_argument(\n",
    "        '-v', '--verbose',\n",
    "        action='store_true',\n",
    "        dest='debug',\n",
    "        help='print debug information')\n",
    "    argparser.add_argument(\n",
    "        '--host',\n",
    "        metavar='H',\n",
    "        default='127.0.0.1',\n",
    "        help='IP of the host server (default: 127.0.0.1)')\n",
    "    argparser.add_argument(\n",
    "        '-p', '--port',\n",
    "        metavar='P',\n",
    "        default=2000,\n",
    "        type=int,\n",
    "        help='TCP port to listen to (default: 2000)')\n",
    "    argparser.add_argument(\n",
    "        '-a', '--autopilot',\n",
    "        action='store_true',\n",
    "        help='enable autopilot')\n",
    "    argparser.add_argument(\n",
    "        '--res',\n",
    "        metavar='WIDTHxHEIGHT',\n",
    "        default='1280x720',\n",
    "        help='window resolution (default: 1280x720)')\n",
    "    argparser.add_argument(\n",
    "        '--filter',\n",
    "        metavar='PATTERN',\n",
    "        default='vehicle.*',\n",
    "        help='actor filter (default: \"vehicle.*\")')\n",
    "    argparser.add_argument(\n",
    "        '--generation',\n",
    "        metavar='G',\n",
    "        default='2',\n",
    "        help='restrict to certain actor generation (values: \"1\",\"2\",\"All\" - default: \"2\")')\n",
    "    argparser.add_argument(\n",
    "        '--rolename',\n",
    "        metavar='NAME',\n",
    "        default='hero',\n",
    "        help='actor role name (default: \"hero\")')\n",
    "    argparser.add_argument(\n",
    "        '--gamma',\n",
    "        default=2.2,\n",
    "        type=float,\n",
    "        help='Gamma correction of the camera (default: 2.2)')\n",
    "    argparser.add_argument(\n",
    "        '--sync',\n",
    "        action='store_true',\n",
    "        help='Activate synchronous mode execution')\n",
    "    argparser.add_argument(\n",
    "        '--maxfps',\n",
    "        default=30,\n",
    "        type=int,\n",
    "        help='Fps of the client (default: 30)')\n",
    "    args = argparser.parse_args()\n",
    "\n",
    "    # Set max fps\n",
    "    # args.maxfps = 60\n",
    "\n",
    "    # Set window resolution\n",
    "    # args.res = '500x300'\n",
    "    args.width, args.height = [int(x) for x in args.res.split('x')]\n",
    "\n",
    "    # Set vehicle filter\n",
    "    args.filter = 'vehicle.mercedes.coupe_2020'\n",
    "\n",
    "    log_level = mc.logging.DEBUG if args.debug else mc.logging.INFO\n",
    "    mc.logging.basicConfig(format='%(levelname)s: %(message)s', level=log_level)\n",
    "\n",
    "    mc.logging.info('listening to server %s:%s', args.host, args.port)\n",
    "\n",
    "    print(mc.__doc__)\n",
    "\n",
    "    return GameLoop(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esecuzione del programma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definizione valori di dimensione\n",
    "\n",
    "- *camera_width* e *camera_height* sono le dimensioni dell'immagine catturata dalla camera\n",
    "- *crop_width*, *crop_height* e *height_adjust* sono i valori della porzione di immagine da analizzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_width = 800\n",
    "camera_height = 600\n",
    "\n",
    "crop_width = 500\n",
    "crop_height = 240\n",
    "height_adjust = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: listening to server 127.0.0.1:2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to CARLA manual control.\n",
      "\n",
      "Use ARROWS or WASD keys for control.\n",
      "\n",
      "    W            : throttle\n",
      "    S            : brake\n",
      "    A/D          : steer left/right\n",
      "    Q            : toggle reverse\n",
      "    Space        : hand-brake\n",
      "\n",
      "    L            : toggle next light type\n",
      "    Z/X          : toggle right/left blinker\n",
      "\n",
      "    TAB          : change sensor position\n",
      "    ` or N       : next sensor\n",
      "    [1-9]        : change to sensor [1-9]\n",
      "    C            : change weather (Shift+C reverse)\n",
      "\n",
      "    F1           : toggle HUD\n",
      "    ESC          : quit\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 139.10107 150\n",
      "\u001b[92mLine right:\u001b[0m 165.80959 170\n",
      "\u001b[94mLine left:\u001b[0m 140.81755 150\n",
      "\u001b[92mLine right:\u001b[0m 167.43063 170\n",
      "\u001b[94mLine left:\u001b[0m 140.99547 150\n",
      "\u001b[92mLine right:\u001b[0m 167.68002 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.86455 170\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.76675 170\n",
      "\u001b[92mLine right:\u001b[0m 169.60289 170\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.86455 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 168.99046 170\n",
      "\u001b[92mLine right:\u001b[0m 166.68936 170\n",
      "\u001b[92mLine right:\u001b[0m 164.14932 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 160.88582 170\n",
      "\u001b[94mLine left:\u001b[0m 157.29865 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 154.83737 150\n",
      "\u001b[94mLine left:\u001b[0m 154.41869 150\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 155.36784 150\n",
      "\u001b[94mLine left:\u001b[0m 156.98734 150\n",
      "\u001b[94mLine left:\u001b[0m 158.65549 150\n",
      "\u001b[94mLine left:\u001b[0m 153.56694 150\n",
      "\u001b[94mLine left:\u001b[0m 155.06328 150\n",
      "\u001b[94mLine left:\u001b[0m 158.92885 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 160.42519 150\n",
      "\u001b[94mLine left:\u001b[0m 160.92398 150\n",
      "\u001b[92mLine right:\u001b[0m 165.074 170\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 157.80658 150\n",
      "\u001b[92mLine right:\u001b[0m 164.02802 170\n",
      "\u001b[92mLine right:\u001b[0m 164.62248 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 168.26315 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 161.44524 170\n",
      "\u001b[92mLine right:\u001b[0m 160.94646 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 161.94402 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 163.31567 170\n",
      "\u001b[92mLine right:\u001b[0m 165.4355 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.05653 170\n",
      "\u001b[92mLine right:\u001b[0m 168.42819 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.9542 170\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.94858 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 150.14429 150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 150.69894 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 150.94833 150\n",
      "\u001b[94mLine left:\u001b[0m 151.94589 150\n",
      "\u001b[94mLine left:\u001b[0m 153.63954 150\n",
      "\u001b[94mLine left:\u001b[0m 152.13577 150\n",
      "\u001b[94mLine left:\u001b[0m 151.88217 150\n",
      "\u001b[94mLine left:\u001b[0m 155.91832 150\n",
      "\u001b[94mLine left:\u001b[0m 161.42276 150\n",
      "\u001b[94mLine left:\u001b[0m 154.81389 150\n",
      "\u001b[92mLine right:\u001b[0m 172.24312 170\n",
      "\u001b[92mLine right:\u001b[0m 168.25224 170\n",
      "\u001b[92mLine right:\u001b[0m 166.30656 170\n",
      "\u001b[92mLine right:\u001b[0m 164.8894 170\n",
      "\u001b[94mLine left:\u001b[0m 162.22316 150\n",
      "\u001b[92mLine right:\u001b[0m 161.87903 170\n",
      "\u001b[92mLine right:\u001b[0m 161.39377 170\n",
      "\u001b[92mLine right:\u001b[0m 162.18793 170\n",
      "\u001b[94mLine left:\u001b[0m 161.94505 150\n",
      "\u001b[94mLine left:\u001b[0m 161.14984 150\n",
      "\u001b[92mLine right:\u001b[0m 162.08406 170\n",
      "\u001b[92mLine right:\u001b[0m 163.12352 170\n",
      "\u001b[92mLine right:\u001b[0m 164.42181 170\n",
      "\u001b[92mLine right:\u001b[0m 164.44223 170\n",
      "\u001b[92mLine right:\u001b[0m 165.59607 170\n",
      "\u001b[92mLine right:\u001b[0m 168.37108 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 154.6892 150\n",
      "\u001b[94mLine left:\u001b[0m 155.06328 150\n",
      "\u001b[94mLine left:\u001b[0m 154.93858 150\n",
      "\u001b[94mLine left:\u001b[0m 155.81146 150\n",
      "\u001b[94mLine left:\u001b[0m 155.43736 150\n",
      "\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 154.19041 150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 154.5645 150\n",
      "\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 153.23083 150\n",
      "\u001b[94mLine left:\u001b[0m 153.2427 150\n",
      "\u001b[94mLine left:\u001b[0m 156.4025 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 157.30597 150\n",
      "\u001b[92mLine right:\u001b[0m 166.26315 170\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 159.33406 150\n",
      "\u001b[92mLine right:\u001b[0m 161.0856 170\n",
      "\u001b[94mLine left:\u001b[0m 159.32558 150\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 160.79337 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 163.62053 170\n",
      "\u001b[92mLine right:\u001b[0m 160.99425 170\n",
      "\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 141.4335 150\n",
      "\u001b[92mLine right:\u001b[0m 168.05411 170\n",
      "\u001b[92mLine right:\u001b[0m 166.18367 170\n",
      "\u001b[92mLine right:\u001b[0m 164.68733 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 164.68733 170\n",
      "\u001b[92mLine right:\u001b[0m 169.48201 170\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 160.30049 150\n",
      "\u001b[94mLine left:\u001b[0m 157.4325 150\n",
      "\u001b[94mLine left:\u001b[0m 155.31267 150\n",
      "\u001b[92mLine right:\u001b[0m 153.9635 170\n",
      "\u001b[94mLine left:\u001b[0m 152.13963 150\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.25659 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.5791 170\n",
      "\u001b[92mLine right:\u001b[0m 165.08052 170\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 164.64363 170\n",
      "\u001b[94mLine left:\u001b[0m 159.52364 150\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 161.71239 170\n",
      "\u001b[92mLine right:\u001b[0m 161.81642 170\n",
      "\u001b[92mLine right:\u001b[0m 160.41142 170\n",
      "\u001b[94mLine left:\u001b[0m 159.14192 150\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 161.85918 170\n",
      "\u001b[92mLine right:\u001b[0m 160.914 170\n",
      "\u001b[92mLine right:\u001b[0m 162.49356 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 161.37723 170\n",
      "\u001b[92mLine right:\u001b[0m 160.95512 170\n",
      "\u001b[92mLine right:\u001b[0m 162.20311 170\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 157.16441 150\n",
      "\u001b[92mLine right:\u001b[0m 159.68814 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 162.55771 170\n",
      "\u001b[94mLine left:\u001b[0m 165.52065 150\n",
      "\u001b[92mLine right:\u001b[0m 165.80959 170\n",
      "\u001b[94mLine left:\u001b[0m 159.80171 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 156.80902 150\n",
      "\u001b[92mLine right:\u001b[0m 159.68613 170\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 159.6149 170\n",
      "\u001b[92mLine right:\u001b[0m 159.74211 170\n",
      "\u001b[92mLine right:\u001b[0m 158.48036 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.17636 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 160.10391 170\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 158.49928 150\n",
      "\u001b[94mLine left:\u001b[0m 155.74225 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 153.41333 150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.30106 170\n",
      "\u001b[92mLine right:\u001b[0m 165.68489 170\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 160.19829 170\n",
      "\u001b[92mLine right:\u001b[0m 157.45499 170\n",
      "\u001b[92mLine right:\u001b[0m 156.9562 170\n",
      "\u001b[92mLine right:\u001b[0m 155.95863 170\n",
      "\u001b[94mLine left:\u001b[0m 157.4325 150\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 158.18066 150\n",
      "\u001b[92mLine right:\u001b[0m 160.57237 170\n",
      "\u001b[94mLine left:\u001b[0m 160.42519 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 159.55232 150\n",
      "\u001b[94mLine left:\u001b[0m 159.55232 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 159.05354 150\n",
      "\u001b[94mLine left:\u001b[0m 157.80658 150\n",
      "\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 155.93616 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 155.18797 150\n",
      "\u001b[94mLine left:\u001b[0m 153.44225 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 152.44467 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 150.82364 150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.11551 170\n",
      "\u001b[92mLine right:\u001b[0m 168.93466 170\n",
      "\u001b[92mLine right:\u001b[0m 168.43646 170\n",
      "\u001b[92mLine right:\u001b[0m 168.08218 170\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.74648 170\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.78761 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.66121 170\n",
      "\u001b[92mLine right:\u001b[0m 167.73822 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.98885 170\n",
      "\u001b[92mLine right:\u001b[0m 167.98964 170\n",
      "\u001b[92mLine right:\u001b[0m 167.81369 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.87234 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.85114 170\n",
      "\u001b[92mLine right:\u001b[0m 167.9337 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 168.54617 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 168.62279 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 168.49077 170\n",
      "\u001b[92mLine right:\u001b[0m 169.05228 170\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.0488 170\n",
      "\u001b[92mLine right:\u001b[0m 169.33537 170\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.28123 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.18173 170\n",
      "\u001b[92mLine right:\u001b[0m 169.2125 170\n",
      "\u001b[92mLine right:\u001b[0m 169.71996 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 163.88622 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 150.07545 150\n",
      "\u001b[94mLine left:\u001b[0m 150.57423 150\n",
      "\u001b[94mLine left:\u001b[0m 151.32242 150\n",
      "\u001b[94mLine left:\u001b[0m 151.6965 150\n",
      "\u001b[94mLine left:\u001b[0m 152.44467 150\n",
      "\u001b[94mLine left:\u001b[0m 152.81876 150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 152.69406 150\n",
      "\u001b[94mLine left:\u001b[0m 151.44711 150\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 150.44954 150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 157.82907 170\n",
      "\u001b[92mLine right:\u001b[0m 155.83394 170\n",
      "\u001b[94mLine left:\u001b[0m 153.31755 150\n",
      "\u001b[92mLine right:\u001b[0m 152.84125 170\n",
      "\u001b[94mLine left:\u001b[0m 152.07059 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 150.44954 150\n",
      "\u001b[94mLine left:\u001b[0m 151.07303 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 151.8212 150\n",
      "\u001b[94mLine left:\u001b[0m 151.8212 150\n",
      "\u001b[94mLine left:\u001b[0m 151.6965 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 151.19772 150\n",
      "\u001b[94mLine left:\u001b[0m 150.07545 150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.83372 170\n",
      "\u001b[92mLine right:\u001b[0m 169.84346 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.6172 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.31427 170\n",
      "\u001b[92mLine right:\u001b[0m 168.7493 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.90588 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.25542 170\n",
      "\u001b[92mLine right:\u001b[0m 167.3741 170\n",
      "\u001b[92mLine right:\u001b[0m 166.88408 170\n",
      "\u001b[92mLine right:\u001b[0m 166.43678 170\n",
      "\u001b[92mLine right:\u001b[0m 166.21187 170\n",
      "\u001b[92mLine right:\u001b[0m 165.90666 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 166.24068 170\n",
      "\u001b[92mLine right:\u001b[0m 166.71864 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.73837 170\n",
      "\u001b[92mLine right:\u001b[0m 168.27744 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 168.22966 170\n",
      "\u001b[92mLine right:\u001b[0m 169.18787 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 168.32137 170\n",
      "\u001b[92mLine right:\u001b[0m 168.62202 170\n",
      "\u001b[92mLine right:\u001b[0m 168.41318 170\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 168.21873 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 168.63141 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.47156 170\n",
      "\u001b[92mLine right:\u001b[0m 167.07368 170\n",
      "\u001b[92mLine right:\u001b[0m 166.97867 170\n",
      "\u001b[92mLine right:\u001b[0m 166.68651 170\n",
      "\u001b[92mLine right:\u001b[0m 166.98486 170\n",
      "\u001b[94mLine left:\u001b[0m 163.2932 150\n",
      "\u001b[92mLine right:\u001b[0m 167.51578 170\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.13889 170\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.74953 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.15237 170\n",
      "\u001b[92mLine right:\u001b[0m 169.27396 170\n",
      "\u001b[92mLine right:\u001b[0m 168.32869 170\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 168.28632 170\n",
      "\u001b[92mLine right:\u001b[0m 168.07907 170\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.89127 170\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.34727 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.07497 170\n",
      "\u001b[92mLine right:\u001b[0m 165.98514 170\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 165.83987 170\n",
      "\u001b[92mLine right:\u001b[0m 166.06807 170\n",
      "\u001b[92mLine right:\u001b[0m 167.25568 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.33829 170\n",
      "\u001b[92mLine right:\u001b[0m 167.38968 170\n",
      "\u001b[92mLine right:\u001b[0m 167.21255 170\n",
      "\u001b[92mLine right:\u001b[0m 167.39912 170\n",
      "\u001b[92mLine right:\u001b[0m 167.34604 170\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 163.79198 150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 163.2932 150\n",
      "\u001b[92mLine right:\u001b[0m 167.32864 170\n",
      "\u001b[94mLine left:\u001b[0m 162.9191 150\n",
      "\u001b[92mLine right:\u001b[0m 165.84457 170\n",
      "\u001b[92mLine right:\u001b[0m 165.93192 170\n",
      "\u001b[92mLine right:\u001b[0m 163.88045 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 159.80171 150\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 166.19012 170\n",
      "\u001b[92mLine right:\u001b[0m 166.5513 170\n",
      "\u001b[94mLine left:\u001b[0m 160.1867 150\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 164.3666 170\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 164.2526 150\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 163.51544 170\n",
      "\u001b[92mLine right:\u001b[0m 162.92816 170\n",
      "\u001b[92mLine right:\u001b[0m 162.91222 170\n",
      "\u001b[92mLine right:\u001b[0m 161.617 170\n",
      "\u001b[92mLine right:\u001b[0m 160.34578 170\n",
      "\u001b[92mLine right:\u001b[0m 160.17155 170\n",
      "\u001b[92mLine right:\u001b[0m 159.77512 170\n",
      "\u001b[92mLine right:\u001b[0m 159.84537 170\n",
      "\u001b[94mLine left:\u001b[0m 158.67468 150\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 158.39032 150\n",
      "\u001b[94mLine left:\u001b[0m 158.28635 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 157.61716 150\n",
      "\u001b[94mLine left:\u001b[0m 155.83719 150\n",
      "\u001b[94mLine left:\u001b[0m 153.93974 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 152.98666 150\n",
      "\u001b[94mLine left:\u001b[0m 151.89175 150\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 150.66682 150\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 175.41115 170\n",
      "\u001b[92mLine right:\u001b[0m 175.16176 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 174.78766 170\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 152.94351 150\n",
      "\n",
      "\n",
      "\u001b[94mLine left:\u001b[0m 152.69406 150\n",
      "\u001b[94mLine left:\u001b[0m 161.74612 150\n",
      "\u001b[94mLine left:\u001b[0m 162.29562 150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.68625 170\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.63113 170\n",
      "\u001b[92mLine right:\u001b[0m 168.77397 170\n",
      "\u001b[92mLine right:\u001b[0m 168.11311 170\n",
      "\u001b[92mLine right:\u001b[0m 167.27046 170\n",
      "\u001b[92mLine right:\u001b[0m 166.26479 170\n",
      "\u001b[92mLine right:\u001b[0m 166.03513 170\n",
      "\u001b[92mLine right:\u001b[0m 167.00621 170\n",
      "\u001b[92mLine right:\u001b[0m 168.46494 170\n",
      "\u001b[92mLine right:\u001b[0m 168.91798 170\n",
      "\u001b[92mLine right:\u001b[0m 169.254 170\n",
      "\u001b[92mLine right:\u001b[0m 169.47202 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.26294 170\n",
      "\u001b[92mLine right:\u001b[0m 168.16228 170\n",
      "\u001b[92mLine right:\u001b[0m 167.59546 170\n",
      "\u001b[92mLine right:\u001b[0m 166.72607 170\n",
      "\u001b[92mLine right:\u001b[0m 166.31775 170\n",
      "\u001b[92mLine right:\u001b[0m 165.94089 170\n",
      "\u001b[92mLine right:\u001b[0m 166.01535 170\n",
      "\u001b[92mLine right:\u001b[0m 166.12607 170\n",
      "\u001b[92mLine right:\u001b[0m 166.50636 170\n",
      "\u001b[92mLine right:\u001b[0m 166.98376 170\n",
      "\u001b[92mLine right:\u001b[0m 167.16495 170\n",
      "\u001b[92mLine right:\u001b[0m 167.3481 170\n",
      "\u001b[92mLine right:\u001b[0m 168.39297 170\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.28835 170\n",
      "\u001b[92mLine right:\u001b[0m 169.08017 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.08017 170\n",
      "\u001b[92mLine right:\u001b[0m 169.11186 170\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 169.0 170\n",
      "\u001b[92mLine right:\u001b[0m 168.46954 170\n",
      "\u001b[92mLine right:\u001b[0m 168.09953 170\n",
      "\u001b[92mLine right:\u001b[0m 168.0 170\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.78775 170\n",
      "\u001b[92mLine right:\u001b[0m 168.0 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.96613 170\n",
      "\n",
      "\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.22954 170\n",
      "\u001b[92mLine right:\u001b[0m 166.93149 170\n",
      "\n",
      "\u001b[92mLine right:\u001b[0m 167.0 170\n",
      "\u001b[92mLine right:\u001b[0m 167.0 170\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remove_all(world)\n",
    "\n",
    "processed_output = Queue()\n",
    "\n",
    "# setup the simulation environment\n",
    "game_loop = setup()\n",
    "\n",
    "# get the vehicle and attach the camera\n",
    "vehicle = world.get_actors().filter('vehicle.*')[0]\n",
    "front_camera = spawn_camera(attach_to=vehicle, transform=carla.Transform(\n",
    "        carla.Location(x=0.3, y=0.0, z=1.5), # posizione dello specchietto retrovisore\n",
    "        carla.Rotation(pitch=-10.0)\n",
    "    ),\n",
    "    sensor_tick=0.1,\n",
    "    width=camera_width, height=camera_height\n",
    ")\n",
    "\n",
    "cv2.namedWindow('Processed image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# callback for the camera\n",
    "def camera_callback(image):\n",
    "    '''\n",
    "    Callback for the camera.\n",
    "\n",
    "    Args:\n",
    "        image: the image captured by the camera\n",
    "    '''\n",
    "    try:\n",
    "        video_output = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "        video_output = video_output[:, :, :3]\n",
    "\n",
    "        # Crop the image (zoom)\n",
    "        start_x = (video_output.shape[1] - crop_width) // 2\n",
    "        start_y = (video_output.shape[0] - crop_height) // 2 - height_adjust\n",
    "        cropped_img = video_output[start_y:start_y + crop_height, start_x:start_x + crop_width]\n",
    "\n",
    "        # process the image in a separate thread\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            executor.submit(lambda: process_image(cropped_img, processed_output))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e.with_traceback())\n",
    "\n",
    "# attach the callback to the camera\n",
    "front_camera.listen(lambda image: camera_callback(image))\n",
    "\n",
    "# start the game loop\n",
    "try:\n",
    "    game_loop.start(processed_output, autopilot=False, detection_center=lanes[0]['detections']['stop']['x'], threshold=10)\n",
    "except KeyboardInterrupt:\n",
    "    cv2.destroyAllWindows()\n",
    "finally:\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
