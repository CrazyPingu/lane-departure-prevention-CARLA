{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla, cv2\n",
    "import numpy as np\n",
    "from skimage.measure import LineModelND, ransac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzioni base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_spectator_to(transform, distance=5.0, x=0, y=0, z=4, yaw=0, pitch=-30, roll=0):\n",
    "    back_location = transform.location - transform.get_forward_vector() * distance\n",
    "    back_location.x += x\n",
    "    back_location.y += y\n",
    "    back_location.z += z\n",
    "    transform.rotation.yaw += yaw\n",
    "    transform.rotation.pitch = pitch\n",
    "    transform.rotation.roll = roll\n",
    "    spectator_transform = carla.Transform(back_location, transform.rotation)\n",
    "    spectator.set_transform(spectator_transform)\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.mercedes.coupe_2020', rotation=None):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    if rotation:\n",
    "        spawn_point.rotation = rotation\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "def draw_on_screen(world, transform, content='O', color=carla.Color(0, 255, 0), life_time=20):\n",
    "    world.debug.draw_string(transform.location, content, color=color, life_time=life_time)\n",
    "\n",
    "def spawn_camera(attach_to=None, transform=carla.Transform(carla.Location(x=1.2, z=1.2), carla.Rotation(pitch=-10)), fov=90.0, width=800, height=600, sensor_tick=0.0):\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera_bp.set_attribute('fov', str(fov))\n",
    "    camera_bp.set_attribute('sensor_tick', str(sensor_tick))\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera\n",
    "\n",
    "def remove_all(world):\n",
    "    for a in world.get_actors().filter('vehicle.*'):\n",
    "        a.destroy()\n",
    "    for a in world.get_actors().filter('sensor.*'):\n",
    "        a.destroy()\n",
    "\n",
    "def proportional_spaced_array(pts, min_value, max_value):\n",
    "    delta_dist = max_value - min_value\n",
    "    pts_max = pts[0]\n",
    "    pts_min = pts[len(pts) - 1]\n",
    "    delta_pts = pts_max - pts_min\n",
    "\n",
    "    buffer = []\n",
    "    for i in range(0, len(pts)):\n",
    "        buffer.append(delta_dist * (pts_max - pts[i]) / delta_pts + min_value)\n",
    "\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warp immagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageWarp():\n",
    "\n",
    "    def __init__(self,img_h=240, img_w=320, offset=150, src=[[50, 240], [200, 240], [0, 0], [320, 0]],dst=[[135, 240], [150, 240], [0, 0], [320, 0]]):\n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "        self.warp_offset = offset\n",
    "        self.src = np.float32(src)\n",
    "        self.dst = np.float32(dst)\n",
    "        self.wmat = cv2.getPerspectiveTransform(self.src, self.dst)\n",
    "        self.wmat_inv = cv2.getPerspectiveTransform(self.dst,self.src)\n",
    "\n",
    "    def img_warp(self, iimg,inv=False, offset=False):\n",
    "        \"\"\"\n",
    "        Warps an image based on the input parameters\n",
    "\n",
    "        Args:\n",
    "            iimg ([type]): RGB / Gray image\n",
    "            inv (bool, optional): invers transformation. Defaults to False.\n",
    "            offset (bool, optional): use offset for warping the image. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            [type]: warped image\n",
    "        \"\"\"\n",
    "\n",
    "        ret = []\n",
    "        timg = None\n",
    "\n",
    "        if offset == True:\n",
    "            timg = iimg[self.warp_offset:self.warp_offset+self.img_h, 0:self.img_w]\n",
    "        else:\n",
    "            timg = iimg\n",
    "\n",
    "        if inv == False:\n",
    "            ret = cv2.warpPerspective(timg,self.wmat , (self.img_w, self.img_h))\n",
    "        else:\n",
    "            ret = cv2.warpPerspective(timg,self.wmat_inv , (self.img_w, self.img_h))\n",
    "        return ret\n",
    "\n",
    "    def pts_unwarp(self,pts):\n",
    "        \"\"\"\n",
    "        Backprojects points from warped image to un-warped image\n",
    "\n",
    "        Args:\n",
    "            pts ([type]): points to backproject\n",
    "\n",
    "        Returns:\n",
    "            [type]: backprojected points\n",
    "        \"\"\"\n",
    "        return cv2.perspectiveTransform (pts, self.wmat_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolatore linee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interpolator():\n",
    "\n",
    "    def __init__(self,max_poly_degree=3):\n",
    "        self.max_poly_degree=max_poly_degree\n",
    "\n",
    "    def interpolate(self,indata=dict(), ip_params={'start':0, 'stop':240, 'steps':20},key='mid', nr_interpolated_points=240, equ_selector=False, debug=False):\n",
    "        \"\"\"\n",
    "        Takes detected points, find the corresponding polynom fits the data.\n",
    "\n",
    "        Args:\n",
    "            indata ([type], optional): detected points. Defaults to dict().\n",
    "            ip_params (dict, optional): interpolation info. Defaults to {'start':0, 'stop':240, 'steps':20}.\n",
    "            key (str, optional): Name of the line. Defaults to 'mid'.\n",
    "            nr_interpolated_points (int, optional): Max number of interpolation points. Defaults to 240.\n",
    "            equ_selector (bool, optional): search the best fitting equation (line / curve, etc.). Defaults to False.\n",
    "            debug (bool, optional): Collects debug info. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            [type]: interpolated points\n",
    "        \"\"\"\n",
    "        data = np.array(indata[0][key])\n",
    "\n",
    "        x_coord = data[:,0]\n",
    "        y_coord = data[:,1]\n",
    "\n",
    "        min_mse_pos = self.max_poly_degree\n",
    "\n",
    "        # polynomial degree selector\n",
    "        if equ_selector == True:\n",
    "            # find the best fit\n",
    "            best_poly = []\n",
    "            best_fit = []\n",
    "            for i in range(0,self.max_poly_degree):\n",
    "                pfit = np.polyfit(y_coord,x_coord,i)\n",
    "                polynom = np.poly1d(pfit)\n",
    "                test_y = polynom(x_coord)\n",
    "                difference= y_coord-test_y\n",
    "                st_d = np.std(difference)\n",
    "                best_poly.append(st_d)\n",
    "                best_fit.append((pfit, polynom))\n",
    "\n",
    "            # select best poly\n",
    "            min_mse_pos = np.argmin(np.array(best_poly))\n",
    "\n",
    "        # order start from 1, position from 0\n",
    "        pfit = np.polyfit(y_coord,x_coord,min_mse_pos)\n",
    "        polynom = np.poly1d(pfit)\n",
    "        # pfit, polynom = best_fit[min_mse_pos]\n",
    "\n",
    "        y_ipp = np.float32(np.linspace(ip_params['start'],ip_params['stop'],ip_params['steps']))\n",
    "        x_ipp = polynom(y_ipp)\n",
    "\n",
    "        ply_coords = np.column_stack((x_ipp,y_ipp))\n",
    "        return {key:ply_coords}\n",
    "\n",
    "    def echidistant_lane(self, warp_obj, unwarped_pts=None, lane_side=1):\n",
    "        buffer = []\n",
    "        dist = 115\n",
    "        dist = proportional_spaced_array(unwarped_pts[0][:, 1], 115, 250)\n",
    "        for i in range(0, len(unwarped_pts[0])):\n",
    "            x = unwarped_pts[0][i][0]\n",
    "            y = unwarped_pts[0][i][1]\n",
    "\n",
    "            nx = x\n",
    "            nx = nx - dist[i] * lane_side\n",
    "\n",
    "            norm_pts = np.float32(np.column_stack((nx, y)))\n",
    "            buffer.append(norm_pts)\n",
    "\n",
    "        buffer = np.array(buffer, dtype=np.float32)\n",
    "        buffer = cv2.perspectiveTransform(buffer, warp_obj.wmat)\n",
    "\n",
    "        return np.array(buffer, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector():\n",
    "    def __init__(self, scan_range={'start':0,'stop':240,'steps':20},scan_window={'height':15,'max_adjust':10}):\n",
    "        self.scan_range = scan_range\n",
    "        self.scan_window = scan_window\n",
    "        self.model = LineModelND()\n",
    "        self.debug = []\n",
    "\n",
    "    def img_filter(self,iimg):\n",
    "        \"\"\"\n",
    "        Filters an RGB image to get the lane boundaries\n",
    "\n",
    "        Args:\n",
    "            iimg ([type]): RGB image\n",
    "\n",
    "        Returns:\n",
    "            [type]: RGB image\n",
    "        \"\"\"\n",
    "        iimg = cv2.cvtColor(iimg,cv2.COLOR_BGR2GRAY)\n",
    "        ciimg = cv2.Canny(iimg,50,250)\n",
    "        ciimg = cv2.morphologyEx(ciimg,cv2.MORPH_DILATE,(1,1),iterations = 5)\n",
    "\n",
    "        siimg = cv2.Sobel(iimg,cv2.CV_8U,1,0,ksize=1)\n",
    "        siimg = cv2.morphologyEx(siimg,cv2.MORPH_DILATE,(1,1),iterations = 5)\n",
    "        ret,siimg= cv2.threshold(siimg,50,255,cv2.THRESH_OTSU)\n",
    "        siimg = cv2.morphologyEx(siimg, cv2.MORPH_CLOSE, (3,3))\n",
    "\n",
    "        iimg= cv2.bitwise_and(ciimg,ciimg,mask=siimg)\n",
    "\n",
    "        return iimg\n",
    "\n",
    "    def get_lane_detections(self,iimg,start={'x':105, 'y':230},stop={'x':135, 'y':230},label='mid', use_RANSAC=True, debug=False):\n",
    "        \"\"\"\n",
    "        Parses the input image, with virtual sensors, detects the peeks and save the points\n",
    "\n",
    "        Args:\n",
    "            iimg ([type]): 1 channel gray image\n",
    "            start (dict, optional): detection area start. Defaults to {'x':105, 'y':230}.\n",
    "            stop (dict, optional): detection area start. Defaults to {'x':135, 'y':230}.\n",
    "            label (str, optional): name of the line. Defaults to 'mid'.\n",
    "            use_RANSAC (bool, optional): Use RANSAC. Defaults to True.\n",
    "            debug (bool, optional): collect debug info. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            [type]: detections coordinates\n",
    "        \"\"\"\n",
    "\n",
    "        adjust = 0\n",
    "        minx = min(start['x'],stop['x'])\n",
    "        maxx = max(start['x'],stop['x']) + adjust\n",
    "        detections = []\n",
    "        for i in range (self.scan_range['start'],self.scan_range['stop'],self.scan_range['steps']):\n",
    "            # detections y coordinate\n",
    "            y = start['y']-i\n",
    "\n",
    "            # get detections from a line\n",
    "            det_line = iimg[y:y+self.scan_window['height'], minx:maxx]\n",
    "\n",
    "            # scan an image segment, sum detection\n",
    "            hist = np.sum(det_line, axis=0)\n",
    "\n",
    "            # get peek location\n",
    "            peek = np.argmax(hist)\n",
    "            # peaks, _ = find_peaks(hist, height=np.average(hist))\n",
    "\n",
    "            # define threshold = average, find peeks, \n",
    "            # update 'sensor location'= peek centered\n",
    "            if hist[peek] > np.average(hist):\n",
    "            # if len(peaks) > 0:\n",
    "            #     # Select the central peak\n",
    "            #     peak = peaks[len(peaks) // 2]\n",
    "\n",
    "                x1 = minx+peek\n",
    "                y1 = y\n",
    "                det_mid_x = minx+len(hist)//2\n",
    "\n",
    "                adjust = x1 - det_mid_x\n",
    "\n",
    "                # apply adjust only if in defined range\n",
    "                if np.abs(adjust) >= self.scan_window['max_adjust']:\n",
    "                    sing = np.sign(adjust)\n",
    "                    adjust = sing * self.scan_window['max_adjust']\n",
    "\n",
    "                minx += adjust\n",
    "                maxx += adjust\n",
    "\n",
    "                #self.buffer.append({label:[x1,y1]})\n",
    "                detections.append([x1,y1])\n",
    "                if debug == True:\n",
    "                    self.debug.append({'detection':[x1,y1], 'detection_mid':[det_mid_x,y1],'rectangle': [minx,y1,minx+len(hist),y1+self.scan_window['height']]}) \n",
    "\n",
    "        if use_RANSAC == True:\n",
    "            _, inliers = self.filter_outliers(detections)\n",
    "            if inliers is not None:\n",
    "                detections = np.array(detections)[inliers]\n",
    "\n",
    "        return detections\n",
    "        # return {label:detections}\n",
    "\n",
    "    def filter_outliers(self,data):\n",
    "        \"\"\"\n",
    "        apply RUNSAC\n",
    "\n",
    "        Args:\n",
    "            data ([type]): data points\n",
    "\n",
    "        Returns:\n",
    "            [type]: filtered list\n",
    "        \"\"\"\n",
    "        model_robust = None\n",
    "        inliers = None\n",
    "\n",
    "        data = np.array(data)\n",
    "        self.model.estimate(data)\n",
    "        try:\n",
    "            model_robust, inliers = ransac(data, LineModelND, min_samples=2, residual_threshold=1, max_trials=200)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return model_robust,inliers\n",
    "\n",
    "    def draw_detections(self, iimg,data):\n",
    "        \"\"\"\n",
    "        Visualize detections\n",
    "\n",
    "        Args:\n",
    "            iimg ([type]): RGB image\n",
    "            data ([type]): points detected\n",
    "\n",
    "        Returns:\n",
    "            [type]: RGB image\n",
    "        \"\"\"\n",
    "        limg = iimg.copy()\n",
    "        for v in data:\n",
    "            cv2.circle(limg,(v[0],v[1]),2,[255],-1)\n",
    "        if len(self.debug)>0:\n",
    "            for v in self.debug:\n",
    "                # window center\n",
    "                cv2.circle(limg, (v['detection_mid'][0],v['detection_mid'][1]+5),1,[255])\n",
    "                # detection rectangle\n",
    "                cv2.rectangle(limg,(v['rectangle'][0],v['rectangle'][1]),(v['rectangle'][2],v['rectangle'][3]),[255],1)\n",
    "\n",
    "        return limg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settaggi per il processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = [[70, 240], [430, 240], [0, 0], [500, 0]]\n",
    "dst = [[155, 270], [165, 270], [0, 0], [320, 0]]\n",
    "scan_range= {'start': 0, 'stop': 240, 'steps': 10}\n",
    "scan_window= {'height': 8, 'max_adjust': 8}\n",
    "offset = 150\n",
    "image_width = 500\n",
    "\n",
    "lanes = [\n",
    "    {'label': 'mid', 'detections': {'start': {'x': 120, 'y': 230}, 'stop': {'x': 160, 'y': 230}}},\n",
    "    {'label': 'right', 'detections': {'start': {'x': 160, 'y': 230}, 'stop': {'x': 200, 'y': 230}}}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oggetti per il processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "warper = ImageWarp(img_w=image_width, offset=offset, src=src, dst=dst)\n",
    "detector = Detector(scan_range=scan_range, scan_window=scan_window)\n",
    "interpolator = Interpolator(max_poly_degree=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing dell'immagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, res):\n",
    "    img = image.copy()\n",
    "    f_img = detector.img_filter(img)\n",
    "    f_w_img = warper.img_warp(f_img,offset=True)\n",
    "    try:\n",
    "        img = image.copy()\n",
    "        # img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        f_img = detector.img_filter(img)\n",
    "        f_w_img = warper.img_warp(f_img,offset=True)\n",
    "\n",
    "        color = [1,1,1]\n",
    "\n",
    "        img_detected_points = f_w_img.copy()\n",
    "        # img_line_fitted = f_w_img.copy()\n",
    "        debug = f_w_img.copy()\n",
    "\n",
    "        detected_points = {}\n",
    "        for i, lane in enumerate(lanes):\n",
    "            detected_points[lane['label']] = detector.get_lane_detections(f_w_img, start=lane['detections']['start'], stop=lane['detections']['stop'], label=lane['label'], use_RANSAC=True, debug=True)\n",
    "\n",
    "            # Disegna l'area di valutazione delle corsie\n",
    "            start_x = lane['detections']['start']['x']\n",
    "            start_y = lane['detections']['start']['y']\n",
    "            stop_x = lane['detections']['stop']['x']\n",
    "            stop_y = lane['detections']['stop']['y']\n",
    "            cv2.rectangle(debug, (start_x, start_y), (stop_x, stop_y), (255, 255, 255), 2)\n",
    "\n",
    "        lane = None\n",
    "        if detected_points['mid'].shape[0] > detected_points['right'].shape[0]:\n",
    "            lane = lanes[0]\n",
    "        else:\n",
    "            lane = lanes[1]\n",
    "\n",
    "        img_detected_points = detector.draw_detections(img_detected_points, detected_points[lane['label']])\n",
    "\n",
    "        interpolated_points = interpolator.interpolate([detected_points], key=lane['label'], equ_selector=False, debug=False)\n",
    "\n",
    "        pts = np.array([interpolated_points[lane['label']]])\n",
    "        cv2.polylines(debug, [np.int32(pts)], False, [255], 2)\n",
    "\n",
    "        unwarped_pts = np.int32(warper.pts_unwarp(pts))\n",
    "        unwarped_pts_offset = np.add(unwarped_pts, [0, offset])\n",
    "\n",
    "        color[i] = 255\n",
    "        cv2.polylines(img, [unwarped_pts_offset], False, color, 2)\n",
    "\n",
    "        # ESTIMATE FROM BEST LANE\n",
    "        ed_pts = np.float32(interpolator.echidistant_lane(warp_obj=warper, unwarped_pts=unwarped_pts, lane_side=1 if lane['label'] == 'right' else -1))\n",
    "        cv2.polylines(debug, [np.int32(ed_pts)], False, [255], 2)\n",
    "\n",
    "        ed_unwarped_pts = np.int32(warper.pts_unwarp(ed_pts))\n",
    "        ed_unwarped_pts_offset = np.add(ed_unwarped_pts, [0, offset])\n",
    "\n",
    "        cv2.polylines(img, [ed_unwarped_pts_offset], False, color, 2)\n",
    "\n",
    "        cv2.rectangle(debug, (160, 220), (160, 250), (255, 255, 255), 2)\n",
    "        concat_img = cv2.hconcat([img, cv2.cvtColor(debug[:, :320], cv2.COLOR_GRAY2RGB)])\n",
    "\n",
    "\n",
    "        res.put(concat_img)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        start_x = lane['detections']['start']['x']\n",
    "        start_y = lane['detections']['start']['y']\n",
    "        stop_x = lane['detections']['stop']['x']\n",
    "        stop_y = lane['detections']['stop']['y']\n",
    "        cv2.rectangle(f_w_img, (start_x, start_y), (stop_x, stop_y), (255, 255, 255), 2)\n",
    "        concat_img = cv2.hconcat([image, cv2.cvtColor(f_w_img[:, :320], cv2.COLOR_GRAY2RGB)])\n",
    "        res.put(concat_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import per il main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.7.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'manual_control' from 'c:\\\\Users\\\\emanu\\\\Desktop\\\\universita\\\\Smart-vehicular-systems\\\\lane-departure-prevention-CARLA\\\\manual_control.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from queue import Queue\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import manual_control\n",
    "from importlib import reload\n",
    "reload(manual_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup per il main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_width = 800\n",
    "camera_height = 600\n",
    "\n",
    "crop_width = 500\n",
    "crop_height = 240\n",
    "height_adjust = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: listening to server 127.0.0.1:2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to CARLA manual control.\n",
      "\n",
      "Use ARROWS or WASD keys for control.\n",
      "\n",
      "    W            : throttle\n",
      "    S            : brake\n",
      "    A/D          : steer left/right\n",
      "    Q            : toggle reverse\n",
      "    Space        : hand-brake\n",
      "\n",
      "    L            : toggle next light type\n",
      "    Z/X          : toggle right/left blinker\n",
      "\n",
      "    TAB          : change sensor position\n",
      "    ` or N       : next sensor\n",
      "    [1-9]        : change to sensor [1-9]\n",
      "    C            : change weather (Shift+C reverse)\n",
      "\n",
      "    F1           : toggle HUD\n",
      "    ESC          : quit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remove_all(world)\n",
    "\n",
    "processed_output = Queue()\n",
    "\n",
    "game_loop = manual_control.setup()\n",
    "\n",
    "vehicle = world.get_actors().filter('vehicle.*')[0]\n",
    "front_camera = spawn_camera(attach_to=vehicle, transform=carla.Transform(\n",
    "        carla.Location(x=0.3, y=0.0, z=1.5), # specchietto retrovisore -> x=0.3, y=0.0, z=1.5), logo = x=2.3, z=0.7\n",
    "        carla.Rotation(pitch=-10.0)\n",
    "    ),\n",
    "    sensor_tick=0.1,\n",
    "    width=camera_width, height=camera_height\n",
    ")\n",
    "\n",
    "video_output = np.zeros((camera_height, camera_width, 4), dtype=np.uint8)\n",
    "\n",
    "cv2.namedWindow('Processed', cv2.WINDOW_NORMAL)\n",
    "\n",
    "def camera_callback(image):\n",
    "    global video_output\n",
    "\n",
    "    try:\n",
    "        video_output = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "        video_output = video_output[:, :, :3]\n",
    "\n",
    "        # Crop the image (zoom)\n",
    "        start_x = (video_output.shape[1] - crop_width) // 2\n",
    "        start_y = (video_output.shape[0] - crop_height) // 2 - height_adjust\n",
    "        cropped_img = video_output[start_y:start_y + crop_height, start_x:start_x + crop_width]\n",
    "        try:\n",
    "            with ThreadPoolExecutor() as executor:\n",
    "                executor.submit(\n",
    "                    lambda: process_image(cropped_img, processed_output),\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e.with_traceback())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emanu\\miniconda3\\envs\\carla-env\\lib\\site-packages\\ipykernel_launcher.py:37: RankWarning: Polyfit may be poorly conditioned\n",
      "c:\\Users\\emanu\\miniconda3\\envs\\carla-env\\lib\\site-packages\\ipykernel_launcher.py:37: RankWarning: Polyfit may be poorly conditioned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt to get argmax of an empty sequence\n",
      "'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emanu\\miniconda3\\envs\\carla-env\\lib\\site-packages\\ipykernel_launcher.py:37: RankWarning: Polyfit may be poorly conditioned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'list' object has no attribute 'shape'\n",
      "'list' object has no attribute 'shape'\n",
      "At least 2 input points needed.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n",
      "Input data must be at least 2D.\n"
     ]
    }
   ],
   "source": [
    "front_camera.listen(lambda image: camera_callback(image))\n",
    "\n",
    "try:\n",
    "    game_loop.start(processed_output, autopilot=True)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nCancelled by user. Bye!')\n",
    "    cv2.destroyAllWindows()\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
