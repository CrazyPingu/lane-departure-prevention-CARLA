{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carla lane departure prevention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import delle librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pygame\n",
    "import math\n",
    "from skimage.measure import LineModelND, ransac\n",
    "from queue import Queue\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import paho.mqtt.client as mqtt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import per utilizzare la tastiera come dispositivo di input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import manual_control as mc\n",
    "from importlib import reload\n",
    "reload(mc)\n",
    "\n",
    "steering_wheel = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import per utilizzare volante e pedaliera come dispositivi di input (necessario modificare *wheel_config.ini* in relazione alla periferica usata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import manual_control_steeringwheel as mc\n",
    "from importlib import reload\n",
    "reload(mc)\n",
    "\n",
    "steering_wheel = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Connessione al server di Carla e creazione degli elementi principali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MQTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "broker = 'a8f1d72a1d534548871999f9745fe414.s1.eu.hivemq.cloud'\n",
    "port = 8883\n",
    "topic = 'carla/lane-departure-prevention'\n",
    "mqtt_username = 'carla-sim'\n",
    "mqtt_password = 'CarlaSimulation1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks per messaggio connessione avvenuta e messaggio ricevuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_connect(client, userdata, flags, rc, properties):\n",
    "    print(f'Connected with result code {rc}')\n",
    "    client.subscribe(topic)\n",
    "\n",
    "def on_message(client, userdata, msg):\n",
    "    print(f'Message received on {msg.topic}: {msg.payload.decode()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodo per inviare messaggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(client, topic, message, wait=False):\n",
    "    result = client.publish(topic, message, qos=1)\n",
    "    if wait:\n",
    "        result.wait_for_publish()\n",
    "    print(f'Message published on {topic}: {message}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connessione al broker MQTT e configurazioni base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MQTTErrorCode.MQTT_ERR_SUCCESS: 0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mqtt_client = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n",
    "mqtt_client.tls_set(tls_version=mqtt.ssl.PROTOCOL_TLS)\n",
    "mqtt_client.username_pw_set(mqtt_username, mqtt_password)\n",
    "mqtt_client.on_connect = on_connect\n",
    "mqtt_client.on_message = on_message\n",
    "mqtt_client.connect(broker, port, 60)\n",
    "\n",
    "mqtt_client.loop_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dizionario con i messaggi possibili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mqtt_messages = {\n",
    "    'left_prevention': 'LEFT lane: departure prevention',\n",
    "    'right_prevention': 'RIGHT lane: departure prevention',\n",
    "    'left_crossed': 'LEFT lane: crossed',\n",
    "    'right_crossed': 'RIGHT lane: crossed'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dichiarazione funzioni base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_spectator_to(transform, distance=5.0, x=0, y=0, z=4, yaw=0, pitch=-30, roll=0):\n",
    "    back_location = transform.location - transform.get_forward_vector() * distance\n",
    "    back_location.x += x\n",
    "    back_location.y += y\n",
    "    back_location.z += z\n",
    "    transform.rotation.yaw += yaw\n",
    "    transform.rotation.pitch = pitch\n",
    "    transform.rotation.roll = roll\n",
    "    spectator_transform = carla.Transform(back_location, transform.rotation)\n",
    "    spectator.set_transform(spectator_transform)\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.mercedes.coupe_2020', rotation=None):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    if rotation:\n",
    "        spawn_point.rotation = rotation\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "def draw_on_screen(world, transform, content='O', color=carla.Color(0, 255, 0), life_time=20):\n",
    "    world.debug.draw_string(transform.location, content, color=color, life_time=life_time)\n",
    "\n",
    "def spawn_camera(attach_to=None, transform=carla.Transform(carla.Location(x=1.2, z=1.2), carla.Rotation(pitch=-10)), fov=90.0, width=800, height=600, sensor_tick=0.0):\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera_bp.set_attribute('fov', str(fov))\n",
    "    camera_bp.set_attribute('sensor_tick', str(sensor_tick))\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera\n",
    "\n",
    "def remove_all(world: carla.World):\n",
    "    '''\n",
    "    Remove all actors and sensors from the world.\n",
    "\n",
    "    Args:\n",
    "        world: the world to remove actors and sensors from\n",
    "    '''\n",
    "    for a in world.get_actors().filter('vehicle.*'):\n",
    "        a.destroy()\n",
    "    for a in world.get_actors().filter('sensor.*'):\n",
    "        a.destroy()\n",
    "\n",
    "def proportional_spaced_array(pts: list, min_value: float, max_value: float):\n",
    "    '''\n",
    "    Generate an array of values that are proportional to the input array in increasing or decreasing.\n",
    "\n",
    "    Args:\n",
    "        pts: the input array\n",
    "        min_value: the minimum value of the output array\n",
    "        max_value: the maximum value of the output array\n",
    "\n",
    "    Returns:\n",
    "        a list of values that are proportional to the input array in increasing or decreasing\n",
    "    '''\n",
    "    delta_dist = max_value - min_value\n",
    "    pts_max = pts[0]\n",
    "    pts_min = pts[len(pts) - 1]\n",
    "    delta_pts = pts_max - pts_min\n",
    "\n",
    "    buffer = []\n",
    "    for i in range(0, len(pts)):\n",
    "        buffer.append(delta_dist * (pts_max - pts[i]) / delta_pts + min_value)\n",
    "\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp immagine\n",
    "\n",
    "*ImageWarp* Ã¨ una classe che fornisce i metodi per deformare un'immagine e per riportarla come originale.\n",
    "\n",
    "Metodi:\n",
    "\n",
    "- **img_warp**: deforma o riporta allo stato originale l'immagine.\n",
    "\n",
    "- **pts_unwarp**: trasforma i punti individuati sull'immagine deformata alla forma che si adatta all'immagine originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected with result code Success\n"
     ]
    }
   ],
   "source": [
    "class ImageWarp():\n",
    "\n",
    "    def __init__(self, img_height=240, img_width=320, offset=150, src=[[50, 240], [200, 240], [0, 0], [320, 0]], dst=[[135, 240], [150, 240], [0, 0], [320, 0]]):\n",
    "        '''\n",
    "        Initialize the ImageWarp object.\n",
    "\n",
    "        Args:\n",
    "            img_height: the height of the image\n",
    "            img_width: the width of the image\n",
    "            offset: the height offset of the image\n",
    "            src: the source points of the image\n",
    "            dst: the destination points of the image\n",
    "        '''\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.warp_offset = offset\n",
    "        self.src = np.float32(src)\n",
    "        self.dst = np.float32(dst)\n",
    "        self.warp_mat = cv2.getPerspectiveTransform(self.src, self.dst)\n",
    "        self.warp_mat_inv = cv2.getPerspectiveTransform(self.dst,self.src)\n",
    "\n",
    "    def img_warp(self, img, inv=False, offset=False):\n",
    "        '''\n",
    "        Warps an image based on the input parameters\n",
    "\n",
    "        Args:\n",
    "            img ([type]): RGB / Gray image\n",
    "            inv: invers transformation. Defaults to False.\n",
    "            offset: use offset for warping the image. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            [type]: warped image\n",
    "        '''\n",
    "        ret = []\n",
    "        temp_img = None\n",
    "\n",
    "        if offset == True:\n",
    "            temp_img = img[self.warp_offset:self.warp_offset+self.img_height, 0:self.img_width]\n",
    "        else:\n",
    "            temp_img = img\n",
    "\n",
    "        if inv == False:\n",
    "            ret = cv2.warpPerspective(temp_img, self.warp_mat, (self.img_width, self.img_height))\n",
    "        else:\n",
    "            ret = cv2.warpPerspective(temp_img, self.warp_mat_inv, (self.img_width, self.img_height))\n",
    "        return ret\n",
    "\n",
    "    def pts_unwarp(self, pts):\n",
    "        '''\n",
    "        Backprojects points from warped image to un-warped image\n",
    "\n",
    "        Args:\n",
    "            pts: points to backproject\n",
    "\n",
    "        Returns:\n",
    "            the backprojected points\n",
    "        '''\n",
    "        return cv2.perspectiveTransform(pts, self.warp_mat_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector dei punti appartenenti alle linee stradali\n",
    "\n",
    "*Detector* Ã¨ una classe che fornisce i metodi per individuare i punti appartenenti alle linee stradali che definiscono la carreggiata.\n",
    "\n",
    "Metodi:\n",
    "\n",
    "- **img_filter**: rileva i bordi nell'immagine (con *Canny* vengono rilevati tutti i bordi, mentre con *Sobel* solo quelli verticali), li dilata per migliorarne la visibilitÃ , applica una soglia per binarizzare l'immagine e combina i risultati per ottenere un'immagine finale con bordi piÃ¹ definiti e continui.\n",
    "\n",
    "- **get_lane_detections**: scansiona verticalmente l'immagine per rilevare i bordi delle corsie, calcola l'istogramma delle rilevazioni, trova i picchi, applica un offset per centrare la finestra di rilevamento, memorizza le coordinate dei picchi di ogni finestra e filtra i punti anomali utilizzando RANSAC (se richiesto mettendo a *True* il relativo parametro).\n",
    "\n",
    "- **draw_detections**: disegna i punti rilevati appartenenti alle linee stradali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector():\n",
    "\n",
    "    def __init__(self, scan_range={'start': 0, 'stop': 240, 'steps': 20}, scan_window={'height': 15, 'max_adjust': 10}):\n",
    "        '''\n",
    "        Initialize the Detector object.\n",
    "\n",
    "        Args:\n",
    "            scan_range: the vertical range of the scan\n",
    "            scan_window: the window of the scan for each step\n",
    "        '''\n",
    "        self.scan_range = scan_range\n",
    "        self.scan_window = scan_window\n",
    "        self.model = LineModelND()\n",
    "\n",
    "    def img_filter(self, img):\n",
    "        '''\n",
    "        Filters an RGB image to get the lane boundaries.\n",
    "\n",
    "        Args:\n",
    "            img ([type]): RGB image\n",
    "\n",
    "        Returns:\n",
    "            [type]: RGB image\n",
    "        '''\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        cimg = cv2.Canny(img, 50, 250)\n",
    "        cimg = cv2.morphologyEx(cimg, cv2.MORPH_DILATE, (1, 1), iterations=5)\n",
    "\n",
    "        simg = cv2.Sobel(img, cv2.CV_8U, 1, 0, ksize=1)\n",
    "        simg = cv2.morphologyEx(simg, cv2.MORPH_DILATE, (1, 1), iterations=5)\n",
    "        _, simg= cv2.threshold(simg, 50, 255, cv2.THRESH_OTSU)\n",
    "        simg = cv2.morphologyEx(simg, cv2.MORPH_CLOSE, (3,3))\n",
    "\n",
    "        img = cv2.bitwise_and(cimg, cimg, mask=simg)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def get_lane_detections(self, img, start={'x': 105, 'y': 230}, stop={'x': 135, 'y': 230}, use_RANSAC=True):\n",
    "        '''\n",
    "        Parses the input image, with virtual sensors, detects the peaks and save the points.\n",
    "\n",
    "        Args:\n",
    "            img ([type]): 1 channel gray image\n",
    "            start: detection area start. Defaults to {'x': 105, 'y': 230}.\n",
    "            stop: detection area start. Defaults to {'x': 135, 'y': 230}.\n",
    "            use_RANSAC: Use RANSAC. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            [type]: detections coordinates\n",
    "        '''\n",
    "        adjust = 0\n",
    "        minx = min(start['x'], stop['x'])\n",
    "        maxx = max(start['x'], stop['x']) + adjust\n",
    "        detections = []\n",
    "        for i in range(self.scan_range['start'], self.scan_range['stop'], self.scan_range['steps']):\n",
    "            # detections y coordinate\n",
    "            y = start['y'] - i\n",
    "\n",
    "            # get detections from a line\n",
    "            det_line = img[y:y + self.scan_window['height'], minx:maxx]\n",
    "\n",
    "            # scan an image segment, sum detection\n",
    "            hist = np.sum(det_line, axis=0)\n",
    "\n",
    "            # get peak location\n",
    "            peak = np.argmax(hist)\n",
    "\n",
    "            # define threshold = average, find peaks\n",
    "            if hist[peak] > np.average(hist):\n",
    "\n",
    "                x1 = minx + peak\n",
    "                y1 = y\n",
    "                det_mid_x = minx + len(hist) // 2\n",
    "\n",
    "                adjust = x1 - det_mid_x\n",
    "\n",
    "                # apply adjust only if in defined range\n",
    "                if np.abs(adjust) >= self.scan_window['max_adjust']:\n",
    "                    sign = np.sign(adjust)\n",
    "                    adjust = sign * self.scan_window['max_adjust']\n",
    "\n",
    "                minx += adjust\n",
    "                maxx += adjust\n",
    "\n",
    "                detections.append([x1, y1])\n",
    "\n",
    "        if use_RANSAC == True:\n",
    "            _, inliers = self.filter_outliers(detections)\n",
    "            if inliers is not None:\n",
    "                detections = np.array(detections)[inliers]\n",
    "        else:\n",
    "            detections = np.array(detections)\n",
    "\n",
    "        return detections\n",
    "\n",
    "    def filter_outliers(self, data):\n",
    "        '''\n",
    "        Apply RUNSAC.\n",
    "\n",
    "        Args:\n",
    "            data ([type]): data points\n",
    "\n",
    "        Returns:\n",
    "            [type]: filtered list\n",
    "        '''\n",
    "        model_robust = None\n",
    "        inliers = None\n",
    "        data = np.array(data)\n",
    "        self.model.estimate(data)\n",
    "\n",
    "        try:\n",
    "            model_robust, inliers = ransac(data, LineModelND, min_samples=2, residual_threshold=1, max_trials=200)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return model_robust, inliers\n",
    "\n",
    "    def draw_detections(self, img, data):\n",
    "        '''\n",
    "        Visualize detections.\n",
    "\n",
    "        Args:\n",
    "            img ([type]): RGB image\n",
    "            data ([type]): points detected\n",
    "\n",
    "        Returns:\n",
    "            [type]: RGB image with detections\n",
    "        '''\n",
    "        limg = img.copy()\n",
    "        for v in data:\n",
    "            cv2.circle(limg, (v[0], v[1]), 2, [255], -1)\n",
    "\n",
    "        return limg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolatore dei punti individuati\n",
    "\n",
    "*Interpolator* Ã¨ una classe che permette di ottenere le linee che meglio approssimano quelle della strada, partendo dai punti rilevati.\n",
    "\n",
    "Metodi:\n",
    "\n",
    "- **interpolate**: esegue l'interpolazione polinomiale sui punti di una corsia rilevata, seleziona il miglior grado del polinomio se richiesto, calcola i valori interpolati e restituisce le coordinate interpolate.\n",
    "\n",
    "- **echidistant_lane**: genera l'altra linea della corsia data la linea identificata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interpolator():\n",
    "\n",
    "    def __init__(self, max_poly_degree=3):\n",
    "        '''\n",
    "        Initialize the Interpolator object.\n",
    "\n",
    "        Args:\n",
    "            max_poly_degree: the maximum polynomial degree\n",
    "        '''\n",
    "        self.max_poly_degree = max_poly_degree\n",
    "\n",
    "    def interpolate(self, pts=dict(), ip_params={'start': 0, 'stop': 240, 'steps': 20}, key='mid', equ_selector=False):\n",
    "        '''\n",
    "        Takes detected points, find the corresponding polynom that fits the data.\n",
    "\n",
    "        Args:\n",
    "            pts ([type], optional): detected points. Defaults to dict().\n",
    "            ip_params (dict, optional): interpolation info. Defaults to {'start': 0, 'stop': 240, 'steps': 20}.\n",
    "            key (str, optional): Name of the line. Defaults to 'mid'.\n",
    "            equ_selector (bool, optional): search the best fitting equation (line / curve, etc.). Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            [type]: interpolated points\n",
    "        '''\n",
    "        data = np.array(pts[0][key])\n",
    "\n",
    "        x_coord = data[:,0]\n",
    "        y_coord = data[:,1]\n",
    "\n",
    "        min_mse_pos = self.max_poly_degree\n",
    "\n",
    "        # polynomial degree selector\n",
    "        if equ_selector == True:\n",
    "            # find the best fit\n",
    "            best_poly = []\n",
    "            best_fit = []\n",
    "            for i in range(0, self.max_poly_degree + 1):\n",
    "                pfit = np.polyfit(y_coord, x_coord,i)\n",
    "                polynom = np.poly1d(pfit)\n",
    "                test_y = polynom(x_coord)\n",
    "                difference = y_coord - test_y\n",
    "                st_d = np.std(difference)\n",
    "                best_poly.append(st_d)\n",
    "                best_fit.append((pfit, polynom))\n",
    "\n",
    "            # select best polynom\n",
    "            min_mse_pos = np.argmin(np.array(best_poly))\n",
    "\n",
    "        # order start from 1, position from 0\n",
    "        pfit = np.polyfit(y_coord, x_coord, min_mse_pos)\n",
    "        polynom = np.poly1d(pfit)\n",
    "\n",
    "        y_ipp = np.float32(np.linspace(ip_params['start'],ip_params['stop'],ip_params['steps']))\n",
    "        x_ipp = polynom(y_ipp)\n",
    "\n",
    "        ply_coords = np.column_stack((x_ipp,y_ipp))\n",
    "        return {key:ply_coords}\n",
    "\n",
    "    def echidistant_lane(self, warper: ImageWarp, lane_pts, init_dist=115, final_dist=250, lane_side=1):\n",
    "        '''\n",
    "        Create echidistant lane based on the input lane points, considering the deformation generated by the prospective of the camera.\n",
    "\n",
    "        Args:\n",
    "            warper: ImageWarp object\n",
    "            lane_pts: points belonging to the lane detected\n",
    "            init_dist: initial distance (width of the roadway at the most distant point from the camera)\n",
    "            final_dist: final distance (width of the roadway at the closest point to the camera)\n",
    "            lane_side: if it is equal to 1, the lane detected is the right one, if it is equal to -1, the lane detected is the left one\n",
    "\n",
    "        Returns:\n",
    "            echidistant generated lane points\n",
    "        '''\n",
    "        buffer = []\n",
    "        dist = init_dist\n",
    "        dist = proportional_spaced_array(lane_pts[0][:, 1], init_dist, final_dist)\n",
    "        # create the lane points echidistant to the passed points\n",
    "        for i in range(0, len(lane_pts[0])):\n",
    "            x = lane_pts[0][i][0]\n",
    "            y = lane_pts[0][i][1]\n",
    "\n",
    "            nx = x\n",
    "            nx = nx - dist[i] * lane_side\n",
    "\n",
    "            norm_pts = np.float32(np.column_stack((nx, y)))\n",
    "            buffer.append(norm_pts)\n",
    "\n",
    "        buffer = np.array(buffer, dtype=np.float32)\n",
    "        buffer = cv2.perspectiveTransform(buffer, warper.warp_mat)\n",
    "\n",
    "        return np.array(buffer, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settaggi per il processing\n",
    "\n",
    "- *src* e *dst* rappresentano l'associazione dei punti dell'immagine di partenza con quelli dell'immagine deformata (es: il punto con coordinate (70, 240) corrisponderÃ  al punto (155, 270) nell'immagine trasformata, in modo analogo gli altri punti)\n",
    "- *scan_range* indica il range verticale nel quale verranno valutati i punti delle linee e il salto da fare per ogni valutazione\n",
    "- *scan_window* rappresenta la finestra nella quale viene cercato un punto appartenente ad una linea\n",
    "- *offset* indica l'offset verticale\n",
    "- *image_width* contiene la larghezza dell'immagine\n",
    "- *lanes* rappresenta le aree nelle quali vengono valutate le linee della carreggiata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src = [[70, 240], [430, 240], [0, 0], [500, 0]]\n",
    "dst = [[155, 270], [165, 270], [0, 0], [320, 0]]\n",
    "\n",
    "scan_range = {'start': 0, 'stop': 240, 'steps': 10}\n",
    "scan_window = {'height': 8, 'max_adjust': 8}\n",
    "offset = 150\n",
    "image_width = 500\n",
    "\n",
    "lanes = [\n",
    "    {'label': 'mid', 'detections': {'start': {'x': 130, 'y': 230}, 'stop': {'x': 160, 'y': 230}}},\n",
    "    {'label': 'right', 'detections': {'start': {'x': 160, 'y': 230}, 'stop': {'x': 190, 'y': 230}}}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Istanziamento degli oggetti per il processing dell'immagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "warper = ImageWarp(img_width=image_width, offset=offset, src=src, dst=dst)\n",
    "detector = Detector(scan_range=scan_range, scan_window=scan_window)\n",
    "interpolator = Interpolator(max_poly_degree=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzione di processing dell'immagine\n",
    "\n",
    "Questa funzione rileva le linee di corsia in un'immagine, le interpola per ottenere curve lisce, le trasforma alla prospettiva originale e salva i risultati in una coda, per la visualizzazione.\n",
    "\n",
    "La linea rilevata viene mostrata in **blu**, mentre la linea generata a partire da quella rilevata viene disegnata in **verde**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, res):\n",
    "    '''\n",
    "    Process the input image, detect lanes, interpolate and draw the echidistant lane.\n",
    "    If an error occurs, the original image with no relevations is put in the result queue.\n",
    "\n",
    "    Args:\n",
    "        image: the input image\n",
    "        res: the queue to put the result\n",
    "    '''\n",
    "    try:\n",
    "        img = image.copy()\n",
    "        f_img = detector.img_filter(img)\n",
    "        f_w_img = warper.img_warp(f_img, offset=True)\n",
    "\n",
    "        color = [1, 1, 1]\n",
    "\n",
    "        # img_detected_points = f_w_img.copy()\n",
    "        debug = f_w_img.copy()\n",
    "\n",
    "        # detect lanes points\n",
    "        detected_points = {}\n",
    "        for i, lane in enumerate(lanes):\n",
    "            detected_points[lane['label']] = detector.get_lane_detections(f_w_img, start=lane['detections']['start'], stop=lane['detections']['stop'], use_RANSAC=True)\n",
    "\n",
    "            # draw detection area\n",
    "            start_x = lane['detections']['start']['x']\n",
    "            start_y = lane['detections']['start']['y']\n",
    "            stop_x = lane['detections']['stop']['x']\n",
    "            stop_y = lane['detections']['stop']['y']\n",
    "            cv2.rectangle(debug, (start_x, start_y), (stop_x, stop_y), (255, 255, 255), 2)\n",
    "\n",
    "        # select the best lane (the one with the most detected points)\n",
    "        lane = None\n",
    "        if detected_points['mid'].shape[0] > detected_points['right'].shape[0]:\n",
    "            lane = lanes[0]\n",
    "        else:\n",
    "            lane = lanes[1]\n",
    "\n",
    "        # img_detected_points = detector.draw_detections(img_detected_points, detected_points[lane['label']])\n",
    "\n",
    "        # interpolate the lane points\n",
    "        interpolated_points = interpolator.interpolate([detected_points], key=lane['label'], equ_selector=False)\n",
    "\n",
    "        pts = np.array([interpolated_points[lane['label']]])\n",
    "        cv2.polylines(debug, [np.int32(pts)], False, [155], 2)\n",
    "\n",
    "        # unwarp the lane points\n",
    "        unwarped_pts = np.int32(warper.pts_unwarp(pts))\n",
    "        unwarped_pts_offset = np.add(unwarped_pts, [0, offset])\n",
    "\n",
    "        color[0] = 255\n",
    "        cv2.polylines(img, [unwarped_pts_offset], False, color, 2)\n",
    "\n",
    "        # estimate the echidistant lane\n",
    "        ed_pts = np.float32(interpolator.echidistant_lane(warper=warper, lane_pts=unwarped_pts, lane_side=1 if lane['label'] == 'right' else -1))\n",
    "        cv2.polylines(debug, [np.int32(ed_pts)], False, [155], 2)\n",
    "\n",
    "        # unwarp the echidistant lane points\n",
    "        ed_unwarped_pts = np.int32(warper.pts_unwarp(ed_pts))\n",
    "        ed_unwarped_pts_offset = np.add(ed_unwarped_pts, [0, offset])\n",
    "\n",
    "        color[0] = 1\n",
    "        color[1] = 255\n",
    "        cv2.polylines(img, [ed_unwarped_pts_offset], False, color, 2)\n",
    "\n",
    "        # draw the separation for the lanes\n",
    "        middle = lanes[0]['detections']['stop']['x']\n",
    "        cv2.rectangle(debug, (middle, lane['detections']['start']['y'] - 10), (middle, lane['detections']['start']['y'] + 10), (255, 255, 255), 2)\n",
    "        concat_img = cv2.hconcat([img, cv2.cvtColor(debug[:, :dst[3][0]], cv2.COLOR_GRAY2RGB)])\n",
    "\n",
    "        ed_pts = ed_pts.reshape(20, 2)\n",
    "        detection_index = len(pts[0]) - 2\n",
    "        left_lane = pts[0][detection_index] if lane['label'] == 'mid' else ed_pts[detection_index]\n",
    "        right_lane = ed_pts[detection_index] if lane['label'] == 'mid' else pts[0][detection_index]\n",
    "        top_left = pts[0][0] if lane['label'] == 'mid' else ed_pts[0]\n",
    "        top_right = ed_pts[0] if lane['label'] == 'mid' else pts[0][0]\n",
    "\n",
    "        res.put({'img': concat_img, 'left_lane': left_lane[0], 'right_lane': right_lane[0], 'far_left': top_left[0], 'far_right': top_right[0]})\n",
    "\n",
    "    except Exception as e:\n",
    "        concat_img = cv2.hconcat([image, cv2.cvtColor(f_w_img[:, :dst[3][0]], cv2.COLOR_GRAY2RGB)])\n",
    "\n",
    "        res.put({'img': concat_img, 'left_lane': None, 'right_lane': None, 'far_left': None, 'far_right': None})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzioni e oggetti provenienti da *manual_control.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'oggetto **GameLoop** e la funzione **setup** sono stati presi da *manual_control.py* e modificati secondo le esigenze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variabili e funzioni utili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *steer_correction_time* rappresenta la durata della correzione dello sterzo per non oltrepassare la linea (dipende dal frame rate massimo impostato).\n",
    "- *min_line_distance* Ã¨ la distanza minima dal centro dell'area di rilevazione, se la linea viene rilevata nell'intervallo [*detection_center - min_line_distance, detection_center + min_line_distance*] allora si ha sorpassato il bordo della carreggiata.\n",
    "- *last_left_lane* e *last_right_lane* contengono rispettivamente il precedente valore della liena di sinistra e di destra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "steer_correction_time = 1\n",
    "min_line_distance = 2\n",
    "\n",
    "last_left_lane = None\n",
    "last_right_lane = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LinesValueTracker** serve a controllare la validitÃ  delle rilevazioni delle linee, controllando che le ultime *history_length* rilevazioni abbiano valori accettabili, ovvero non troppo diversi tra loro (questa funzionalitÃ  Ã¨ utile principalmente in prossimitÃ  delle strisce pedonali per evitare il problema che queste ultime possono causare, in quanto esse possono confondere l'algoritmo di riconoscimento delle linee della carreggiata utilizzato, visto che sono una successione di linee verticali parallele che rendono molto difficile all'algoritmo la distinzione di esse da quelle corrette)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinesValueTracker:\n",
    "    def __init__(self, history_length=3):\n",
    "        '''\n",
    "        Initialize the LinesValueTracker object.\n",
    "\n",
    "        Args:\n",
    "            history_length: the length of the history\n",
    "        '''\n",
    "        self.left_history = []\n",
    "        self.right_history = []\n",
    "        self.history_length = history_length\n",
    "\n",
    "    def add_values(self, left, right):\n",
    "        '''\n",
    "        Add the last values of the left and right lanes detection.\n",
    "\n",
    "        Args:\n",
    "            left: the last value of the left lane detection\n",
    "            right: the last value of the right lane detection\n",
    "        '''\n",
    "        self.left_history.append(left)\n",
    "        self.right_history.append(right)\n",
    "\n",
    "        # Mantieni solo gli ultimi 3 valori\n",
    "        if len(self.left_history) > self.history_length:\n",
    "            self.left_history.pop(0)\n",
    "        if len(self.right_history) > self.history_length:\n",
    "            self.right_history.pop(0)\n",
    "\n",
    "    def are_detections_valid(self, threshold=10):\n",
    "        '''\n",
    "        Verify if the last values are valid.\n",
    "\n",
    "        Returns:\n",
    "            True if the last values are valid, False otherwise\n",
    "        '''\n",
    "        if len(self.left_history) < self.history_length or len(self.right_history) < self.history_length:\n",
    "            return False\n",
    "\n",
    "        # Controlla se gli ultimi 3 valori di left e right sono simili\n",
    "        left_similar = all(abs(self.left_history[i] - self.left_history[i-1]) < threshold for i in range(1, self.history_length))\n",
    "        right_similar = all(abs(self.right_history[i] - self.right_history[i-1]) < threshold for i in range(1, self.history_length))\n",
    "\n",
    "        return left_similar and right_similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game loop e setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameLoop(object):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        pygame.init()\n",
    "        pygame.font.init()\n",
    "        self.world = None\n",
    "        self.original_settings = None\n",
    "        self.fps = args.maxfps\n",
    "        self.validator = LinesValueTracker()\n",
    "\n",
    "        try:\n",
    "            self.sim_world = client.get_world()\n",
    "            if args.sync:\n",
    "                self.original_settings = self.sim_world.get_settings()\n",
    "                settings = self.sim_world.get_settings()\n",
    "                if not settings.synchronous_mode:\n",
    "                    settings.synchronous_mode = True\n",
    "                    settings.fixed_delta_seconds = 0.05\n",
    "                self.sim_world.apply_settings(settings)\n",
    "\n",
    "                traffic_manager = client.get_trafficmanager()\n",
    "                traffic_manager.set_synchronous_mode(True)\n",
    "\n",
    "            if not self.sim_world.get_settings().synchronous_mode:\n",
    "                print('WARNING: You are currently in asynchronous mode and could '\n",
    "                    'experience some issues with the traffic simulation')\n",
    "\n",
    "            self.display = pygame.display.set_mode(\n",
    "                (args.width, args.height),\n",
    "                pygame.HWSURFACE | pygame.DOUBLEBUF)\n",
    "            self.display.fill((0,0,0))\n",
    "            pygame.display.flip()\n",
    "\n",
    "            hud = mc.HUD(args.width, args.height)\n",
    "            self.world = mc.World(self.sim_world, hud, args)\n",
    "            self.controller = None\n",
    "            if steering_wheel:\n",
    "                self.controller = mc.DualControl(self.world)\n",
    "            else:\n",
    "                self.controller = mc.KeyboardControl()\n",
    "\n",
    "            if args.sync:\n",
    "                self.sim_world.tick()\n",
    "            else:\n",
    "                self.sim_world.wait_for_tick()\n",
    "        except Exception:\n",
    "            mc.logging.exception('Error creating the world')\n",
    "\n",
    "    def get_speed(self, vehicle: carla.Vehicle):\n",
    "        '''\n",
    "        Get the speed of the vehicle.\n",
    "\n",
    "        Args:\n",
    "            vehicle: the vehicle to get the speed from\n",
    "\n",
    "        Returns:\n",
    "            the speed of the vehicle\n",
    "        '''\n",
    "        velocity = vehicle.get_velocity()\n",
    "        speed = math.sqrt(velocity.x**2 + velocity.y**2 + velocity.z**2)\n",
    "        return speed\n",
    "\n",
    "    def render(self, clock: pygame.time.Clock):\n",
    "        '''\n",
    "        Render the world and make the simulation tick.\n",
    "\n",
    "        Args:\n",
    "            clock: the clock to control the frame rate\n",
    "        '''\n",
    "        self.world.tick(clock)\n",
    "        self.world.render(self.display)\n",
    "        pygame.display.flip()\n",
    "\n",
    "    def get_blinkers_state(self):\n",
    "        '''\n",
    "        Get the state of the blinkers of the player.\n",
    "\n",
    "        Returns:\n",
    "            the state of the left and right blinkers\n",
    "        '''\n",
    "        light_state = self.world.player.get_light_state()\n",
    "        left_blinker = light_state & carla.VehicleLightState.LeftBlinker\n",
    "        right_blinker = light_state & carla.VehicleLightState.RightBlinker\n",
    "        return left_blinker, right_blinker\n",
    "\n",
    "    def start(self, processed_output, autopilot=False, detection_center=100, threshold=20):\n",
    "        '''\n",
    "        Starts the application loop.\n",
    "\n",
    "        Args:\n",
    "            processed_output: the queue to get the processed image\n",
    "            autopilot: if True, the player will be controlled by the autopilot\n",
    "            detection_center: the center of the detection area\n",
    "            threshold: the threshold to detect if the player is going to cross the lane\n",
    "        '''\n",
    "        self.world.player.set_autopilot(autopilot)\n",
    "        try:\n",
    "            clock = pygame.time.Clock()\n",
    "            while True:\n",
    "                if self.args.sync:\n",
    "                    self.sim_world.tick()\n",
    "                clock.tick_busy_loop(self.fps)\n",
    "\n",
    "                if self.controller.parse_events(self.world, clock):\n",
    "                    return\n",
    "\n",
    "                # Show processed camera output\n",
    "                try:\n",
    "                    # output = processed_output.get_nowait()\n",
    "                    output = processed_output.get()\n",
    "\n",
    "                    if output['left_lane'] is not None and output['right_lane'] is not None:\n",
    "\n",
    "                        # steer_cache is used to apply small steering corrections.\n",
    "                        steer_cache = None\n",
    "                        # correction_applied = False\n",
    "                        left_blinker, right_blinker = self.get_blinkers_state()\n",
    "\n",
    "                        left = output['left_lane']\n",
    "                        right = output['right_lane']\n",
    "                        self.validator.add_values(left, right)\n",
    "\n",
    "                        # Check if the detections are valid and the reverse is not inserted, then apply the steering correction if needed\n",
    "                        if self.validator.are_detections_valid() and self.world.player.get_control().gear != -1:\n",
    "                            speed = self.get_speed(self.world.player)\n",
    "\n",
    "                            throttle = min(0.3, self.world.player.get_control().throttle)\n",
    "                            # steer applyed is inversely proportional to the speed\n",
    "                            steer_cache = 0.35 - speed / 100\n",
    "\n",
    "                            # Left lane departure prevention\n",
    "                            if not left_blinker:\n",
    "                                if (left > detection_center - threshold) and speed > 0:\n",
    "                                    if left >= detection_center - max(min_line_distance, threshold // 5):\n",
    "                                        send_message(mqtt_client, topic, mqtt_messages['left_crossed'])\n",
    "                                        self.world.hud.notification(mqtt_messages['left_crossed'])\n",
    "                                    else:\n",
    "                                        send_message(mqtt_client, topic, mqtt_messages['left_prevention'])\n",
    "                                        self.world.hud.notification(mqtt_messages['left_prevention'])\n",
    "\n",
    "                                    # print(f'\\033[94mLine left:\\033[0m', left, detection_center - threshold)\n",
    "                                    steer_cache = steer_cache\n",
    "                                    self.world.player.apply_control(carla.VehicleControl(steer=steer_cache, throttle=throttle))\n",
    "\n",
    "                            # Right lane departure prevention\n",
    "                            if not right_blinker:\n",
    "                                if (right < detection_center + threshold) and speed > 0:\n",
    "                                    if right <= detection_center + max(min_line_distance, threshold // 5):\n",
    "                                        send_message(mqtt_client, topic, mqtt_messages['right_crossed'])\n",
    "                                        self.world.hud.notification(mqtt_messages['right_crossed'])\n",
    "                                    else:\n",
    "                                        send_message(mqtt_client, topic, mqtt_messages['right_prevention'])\n",
    "                                        self.world.hud.notification(mqtt_messages['right_prevention'])\n",
    "\n",
    "                                    # print('\\033[92mLine right:\\033[0m', right, detection_center + threshold)\n",
    "                                    steer_cache = -steer_cache\n",
    "                                    self.world.player.apply_control(carla.VehicleControl(steer=steer_cache, throttle=throttle))\n",
    "\n",
    "                    cv2.imshow('Processed image', output['img'])\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "                self.render(clock)\n",
    "\n",
    "                cv2.waitKey(1)\n",
    "        finally:\n",
    "\n",
    "            if self.original_settings:\n",
    "                self.sim_world.apply_settings(self.original_settings)\n",
    "\n",
    "            if self.world is not None:\n",
    "                self.world.destroy()\n",
    "\n",
    "            pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    argparser = mc.argparse.ArgumentParser(description='CARLA Manual Control Client')\n",
    "    argparser.add_argument(\n",
    "        '-v', '--verbose',\n",
    "        action='store_true',\n",
    "        dest='debug',\n",
    "        help='print debug information')\n",
    "    argparser.add_argument(\n",
    "        '--host',\n",
    "        metavar='H',\n",
    "        default='127.0.0.1',\n",
    "        help='IP of the host server (default: 127.0.0.1)')\n",
    "    argparser.add_argument(\n",
    "        '-p', '--port',\n",
    "        metavar='P',\n",
    "        default=2000,\n",
    "        type=int,\n",
    "        help='TCP port to listen to (default: 2000)')\n",
    "    argparser.add_argument(\n",
    "        '--res',\n",
    "        metavar='WIDTHxHEIGHT',\n",
    "        default='1280x720',\n",
    "        help='window resolution (default: 1280x720)')\n",
    "    argparser.add_argument(\n",
    "        '--filter',\n",
    "        metavar='PATTERN',\n",
    "        default='vehicle.*',\n",
    "        help='actor filter (default: \"vehicle.*\")')\n",
    "    argparser.add_argument(\n",
    "        '--generation',\n",
    "        metavar='G',\n",
    "        default='2',\n",
    "        help='restrict to certain actor generation (values: \"1\", \"2\", \"All\" - default: \"2\")')\n",
    "    argparser.add_argument(\n",
    "        '--rolename',\n",
    "        metavar='NAME',\n",
    "        default='hero',\n",
    "        help='actor role name (default: \"hero\")')\n",
    "    argparser.add_argument(\n",
    "        '--gamma',\n",
    "        default=2.2,\n",
    "        type=float,\n",
    "        help='Gamma correction of the camera (default: 2.2)')\n",
    "    argparser.add_argument(\n",
    "        '--sync',\n",
    "        action='store_true',\n",
    "        help='Activate synchronous mode execution')\n",
    "    argparser.add_argument(\n",
    "        '--maxfps',\n",
    "        default=30,\n",
    "        type=int,\n",
    "        help='Fps of the client (default: 30)')\n",
    "    args = argparser.parse_args()\n",
    "\n",
    "    # Set max fps\n",
    "    # args.maxfps = 60\n",
    "\n",
    "    # Set window resolution\n",
    "    # args.res = '500x300'\n",
    "    args.width, args.height = [int(x) for x in args.res.split('x')]\n",
    "\n",
    "    # Set vehicle filter\n",
    "    args.filter = 'vehicle.mercedes.coupe_2020'\n",
    "\n",
    "    # Set synchronous mode\n",
    "    args.sync = True\n",
    "\n",
    "    log_level = mc.logging.DEBUG if args.debug else mc.logging.INFO\n",
    "    mc.logging.basicConfig(format='%(levelname)s: %(message)s', level=log_level)\n",
    "\n",
    "    mc.logging.info('listening to server %s:%s', args.host, args.port)\n",
    "\n",
    "    print(mc.__doc__)\n",
    "\n",
    "    return GameLoop(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esecuzione del programma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definizione valori di dimensione\n",
    "\n",
    "- *camera_width* e *camera_height* sono le dimensioni dell'immagine catturata dalla camera\n",
    "- *crop_width*, *crop_height* e *height_adjust* sono i valori della porzione di immagine da analizzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_width = 800\n",
    "camera_height = 600\n",
    "\n",
    "crop_width = image_width\n",
    "crop_height = 240\n",
    "height_adjust = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: listening to server 127.0.0.1:2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to CARLA manual control.\n",
      "\n",
      "Use ARROWS or WASD keys for control.\n",
      "\n",
      "    W            : throttle\n",
      "    S            : brake\n",
      "    A/D          : steer left/right\n",
      "    Q            : toggle reverse\n",
      "    Space        : hand-brake\n",
      "\n",
      "    L            : toggle next light type\n",
      "    Z/X          : toggle right/left blinker\n",
      "\n",
      "    TAB          : change sensor position\n",
      "    ` or N       : next sensor\n",
      "    [1-9]        : change to sensor [1-9]\n",
      "    C            : change weather (Shift+C reverse)\n",
      "\n",
      "    H            : toggle help\n",
      "    F1           : toggle HUD\n",
      "    ESC          : quit\n",
      "\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: LEFT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message published on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n",
      "Message received on carla/lane-departure-prevention: RIGHT lane: departure prevention\n"
     ]
    }
   ],
   "source": [
    "remove_all(world)\n",
    "\n",
    "processed_output = Queue()\n",
    "\n",
    "# setup the simulation environment\n",
    "game_loop = setup()\n",
    "\n",
    "# get the vehicle and attach the camera\n",
    "vehicle = world.get_actors().filter('vehicle.*')[0]\n",
    "front_camera = spawn_camera(attach_to=vehicle, transform=carla.Transform(\n",
    "        carla.Location(x=0.3, y=0.0, z=1.5), # posizione dello specchietto retrovisore\n",
    "        carla.Rotation(pitch=-10.0)\n",
    "    ),\n",
    "    # sensor_tick=0.1,\n",
    "    width=camera_width, height=camera_height\n",
    ")\n",
    "\n",
    "cv2.namedWindow('Processed image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# callback for the camera\n",
    "def camera_callback(image):\n",
    "    '''\n",
    "    Callback for the camera.\n",
    "\n",
    "    Args:\n",
    "        image: the image captured by the camera\n",
    "    '''\n",
    "    try:\n",
    "        video_output = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "        video_output = video_output[:, :, :3]\n",
    "\n",
    "        # Crop the image (zoom)\n",
    "        start_x = (video_output.shape[1] - crop_width) // 2\n",
    "        start_y = (video_output.shape[0] - crop_height) // 2 - height_adjust\n",
    "        cropped_img = video_output[start_y:start_y + crop_height, start_x:start_x + crop_width]\n",
    "\n",
    "        # process the image in a separate thread\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            executor.submit(lambda: process_image(cropped_img, processed_output))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e.with_traceback())\n",
    "\n",
    "# attach the callback to the camera\n",
    "front_camera.listen(lambda image: camera_callback(image))\n",
    "\n",
    "# closes the gui and disconnects the mqtt client\n",
    "def cleanup():\n",
    "    cv2.destroyAllWindows()\n",
    "    mqtt_client.loop_stop()\n",
    "    mqtt_client.disconnect()\n",
    "\n",
    "# start the game loop\n",
    "try:\n",
    "    game_loop.start(processed_output, autopilot=False, detection_center=lanes[0]['detections']['stop']['x'], threshold=7)\n",
    "except KeyboardInterrupt:\n",
    "    cleanup()\n",
    "finally:\n",
    "    cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
