{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carla lane departure prevention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import delle librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'manual_control' from 'c:\\\\Users\\\\emanu\\\\Desktop\\\\universita\\\\Smart-vehicular-systems\\\\lane-departure-prevention-CARLA\\\\manual_control.py'>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import carla, cv2\n",
    "import numpy as np\n",
    "from skimage.measure import LineModelND, ransac\n",
    "from queue import Queue\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import manual_control\n",
    "from importlib import reload\n",
    "reload(manual_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Connessione al server di Carla e creazione degli elementi principali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dichiarazione funzioni base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_spectator_to(transform, distance=5.0, x=0, y=0, z=4, yaw=0, pitch=-30, roll=0):\n",
    "    back_location = transform.location - transform.get_forward_vector() * distance\n",
    "    back_location.x += x\n",
    "    back_location.y += y\n",
    "    back_location.z += z\n",
    "    transform.rotation.yaw += yaw\n",
    "    transform.rotation.pitch = pitch\n",
    "    transform.rotation.roll = roll\n",
    "    spectator_transform = carla.Transform(back_location, transform.rotation)\n",
    "    spectator.set_transform(spectator_transform)\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.mercedes.coupe_2020', rotation=None):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    if rotation:\n",
    "        spawn_point.rotation = rotation\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "def draw_on_screen(world, transform, content='O', color=carla.Color(0, 255, 0), life_time=20):\n",
    "    world.debug.draw_string(transform.location, content, color=color, life_time=life_time)\n",
    "\n",
    "def spawn_camera(attach_to=None, transform=carla.Transform(carla.Location(x=1.2, z=1.2), carla.Rotation(pitch=-10)), fov=90.0, width=800, height=600, sensor_tick=0.0):\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera_bp.set_attribute('fov', str(fov))\n",
    "    camera_bp.set_attribute('sensor_tick', str(sensor_tick))\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera\n",
    "\n",
    "def remove_all(world: carla.World):\n",
    "    '''\n",
    "    Remove all actors and sensors from the world.\n",
    "\n",
    "    Args:\n",
    "        world: the world to remove actors and sensors from\n",
    "    '''\n",
    "    for a in world.get_actors().filter('vehicle.*'):\n",
    "        a.destroy()\n",
    "    for a in world.get_actors().filter('sensor.*'):\n",
    "        a.destroy()\n",
    "\n",
    "def proportional_spaced_array(pts: list, min_value: float, max_value: float):\n",
    "    '''\n",
    "    Generate an array of values that are proportional to the input array in increasing or decreasing.\n",
    "\n",
    "    Args:\n",
    "        pts: the input array\n",
    "        min_value: the minimum value of the output array\n",
    "        max_value: the maximum value of the output array\n",
    "\n",
    "    Returns:\n",
    "        a list of values that are proportional to the input array in increasing or decreasing\n",
    "    '''\n",
    "    delta_dist = max_value - min_value\n",
    "    pts_max = pts[0]\n",
    "    pts_min = pts[len(pts) - 1]\n",
    "    delta_pts = pts_max - pts_min\n",
    "\n",
    "    buffer = []\n",
    "    for i in range(0, len(pts)):\n",
    "        buffer.append(delta_dist * (pts_max - pts[i]) / delta_pts + min_value)\n",
    "\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp immagine\n",
    "\n",
    "*ImageWarp* è una classe che fornisce i metodi per deformare un'immagine e per riportarla come originale.\n",
    "\n",
    "Metodi:\n",
    "\n",
    "- **img_warp**: deforma o riporta allo stato originale l'immagine.\n",
    "\n",
    "- **pts_unwarp**: trasforma i punti individuati sull'immagine deformata alla forma che si adatta all'immagine originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageWarp():\n",
    "\n",
    "    def __init__(self, img_height=240, img_width=320, offset=150, src=[[50, 240], [200, 240], [0, 0], [320, 0]], dst=[[135, 240], [150, 240], [0, 0], [320, 0]]):\n",
    "        '''\n",
    "        Initialize the ImageWarp object.\n",
    "\n",
    "        Args:\n",
    "            img_height: the height of the image\n",
    "            img_width: the width of the image\n",
    "            offset: the height offset of the image\n",
    "            src: the source points of the image\n",
    "            dst: the destination points of the image\n",
    "        '''\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.warp_offset = offset\n",
    "        self.src = np.float32(src)\n",
    "        self.dst = np.float32(dst)\n",
    "        self.warp_mat = cv2.getPerspectiveTransform(self.src, self.dst)\n",
    "        self.warp_mat_inv = cv2.getPerspectiveTransform(self.dst,self.src)\n",
    "\n",
    "    def img_warp(self, img, inv=False, offset=False):\n",
    "        '''\n",
    "        Warps an image based on the input parameters\n",
    "\n",
    "        Args:\n",
    "            img ([type]): RGB / Gray image\n",
    "            inv: invers transformation. Defaults to False.\n",
    "            offset: use offset for warping the image. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            [type]: warped image\n",
    "        '''\n",
    "        ret = []\n",
    "        temp_img = None\n",
    "\n",
    "        if offset == True:\n",
    "            temp_img = img[self.warp_offset:self.warp_offset+self.img_height, 0:self.img_width]\n",
    "        else:\n",
    "            temp_img = img\n",
    "\n",
    "        if inv == False:\n",
    "            ret = cv2.warpPerspective(temp_img, self.warp_mat, (self.img_width, self.img_height))\n",
    "        else:\n",
    "            ret = cv2.warpPerspective(temp_img, self.warp_mat_inv, (self.img_width, self.img_height))\n",
    "        return ret\n",
    "\n",
    "    def pts_unwarp(self, pts):\n",
    "        '''\n",
    "        Backprojects points from warped image to un-warped image\n",
    "\n",
    "        Args:\n",
    "            pts: points to backproject\n",
    "\n",
    "        Returns:\n",
    "            the backprojected points\n",
    "        '''\n",
    "        return cv2.perspectiveTransform(pts, self.warp_mat_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector dei punti appartenenti alle linee stradali\n",
    "\n",
    "*Detector* è una classe che fornisce i metodi per individuare i punti appartenenti alle linee stradali che definiscono la carreggiata.\n",
    "\n",
    "Metodi:\n",
    "\n",
    "- **img_filter**: rileva i bordi nell'immagine (con *Canny* vengono rilevati tutti i bordi, mentre con *Sobel* solo quelli verticali), li dilata per migliorarne la visibilità, applica una soglia per binarizzare l'immagine e combina i risultati per ottenere un'immagine finale con bordi più definiti e continui.\n",
    "\n",
    "- **get_lane_detections**: scansiona verticalmente l'immagine per rilevare i bordi delle corsie, calcola l'istogramma delle rilevazioni, trova i picchi, applica un offset per centrare la finestra di rilevamento, memorizza le coordinate dei picchi e filtra i punti anomali utilizzando RANSAC.\n",
    "\n",
    "- **draw_detections**: disegna i punti rilevati appartenenti alle linee stradali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector():\n",
    "\n",
    "    def __init__(self, scan_range={'start': 0, 'stop': 240, 'steps': 20}, scan_window={'height': 15, 'max_adjust': 10}):\n",
    "        '''\n",
    "        Initialize the Detector object.\n",
    "\n",
    "        Args:\n",
    "            scan_range: the vertical range of the scan\n",
    "            scan_window: the window of the scan for each step\n",
    "        '''\n",
    "        self.scan_range = scan_range\n",
    "        self.scan_window = scan_window\n",
    "        self.model = LineModelND()\n",
    "\n",
    "    def img_filter(self, img):\n",
    "        '''\n",
    "        Filters an RGB image to get the lane boundaries.\n",
    "\n",
    "        Args:\n",
    "            img ([type]): RGB image\n",
    "\n",
    "        Returns:\n",
    "            [type]: RGB image\n",
    "        '''\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        cimg = cv2.Canny(img, 50, 250)\n",
    "        cimg = cv2.morphologyEx(cimg, cv2.MORPH_DILATE, (1, 1), iterations=5)\n",
    "\n",
    "        simg = cv2.Sobel(img, cv2.CV_8U, 1, 0, ksize=1)\n",
    "        simg = cv2.morphologyEx(simg, cv2.MORPH_DILATE, (1, 1), iterations=5)\n",
    "        _, simg= cv2.threshold(simg, 50, 255, cv2.THRESH_OTSU)\n",
    "        simg = cv2.morphologyEx(simg, cv2.MORPH_CLOSE, (3,3))\n",
    "\n",
    "        img = cv2.bitwise_and(cimg, cimg, mask=simg)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def get_lane_detections(self, img, start={'x': 105, 'y': 230}, stop={'x': 135, 'y': 230}, use_RANSAC=True):\n",
    "        '''\n",
    "        Parses the input image, with virtual sensors, detects the peaks and save the points.\n",
    "\n",
    "        Args:\n",
    "            img ([type]): 1 channel gray image\n",
    "            start: detection area start. Defaults to {'x': 105, 'y': 230}.\n",
    "            stop: detection area start. Defaults to {'x': 135, 'y': 230}.\n",
    "            use_RANSAC: Use RANSAC. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            [type]: detections coordinates\n",
    "        '''\n",
    "        adjust = 0\n",
    "        minx = min(start['x'], stop['x'])\n",
    "        maxx = max(start['x'], stop['x']) + adjust\n",
    "        detections = []\n",
    "        for i in range (self.scan_range['start'], self.scan_range['stop'], self.scan_range['steps']):\n",
    "            # detections y coordinate\n",
    "            y = start['y'] - i\n",
    "\n",
    "            # get detections from a line\n",
    "            det_line = img[y:y + self.scan_window['height'], minx:maxx]\n",
    "\n",
    "            # scan an image segment, sum detection\n",
    "            hist = np.sum(det_line, axis=0)\n",
    "\n",
    "            # get peak location\n",
    "            peak = np.argmax(hist)\n",
    "\n",
    "            # define threshold = average, find peaks\n",
    "            if hist[peak] > np.average(hist):\n",
    "\n",
    "                x1 = minx + peak\n",
    "                y1 = y\n",
    "                det_mid_x = minx + len(hist) // 2\n",
    "\n",
    "                adjust = x1 - det_mid_x\n",
    "\n",
    "                # apply adjust only if in defined range\n",
    "                if np.abs(adjust) >= self.scan_window['max_adjust']:\n",
    "                    sign = np.sign(adjust)\n",
    "                    adjust = sign * self.scan_window['max_adjust']\n",
    "\n",
    "                minx += adjust\n",
    "                maxx += adjust\n",
    "\n",
    "                detections.append([x1, y1])\n",
    "\n",
    "        if use_RANSAC == True:\n",
    "            _, inliers = self.filter_outliers(detections)\n",
    "            if inliers is not None:\n",
    "                detections = np.array(detections)[inliers]\n",
    "\n",
    "        return detections\n",
    "\n",
    "    def filter_outliers(self, data):\n",
    "        '''\n",
    "        Apply RUNSAC.\n",
    "\n",
    "        Args:\n",
    "            data ([type]): data points\n",
    "\n",
    "        Returns:\n",
    "            [type]: filtered list\n",
    "        '''\n",
    "        model_robust = None\n",
    "        inliers = None\n",
    "        data = np.array(data)\n",
    "        self.model.estimate(data)\n",
    "\n",
    "        try:\n",
    "            model_robust, inliers = ransac(data, LineModelND, min_samples=2, residual_threshold=1, max_trials=200)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return model_robust, inliers\n",
    "\n",
    "    def draw_detections(self, img, data):\n",
    "        '''\n",
    "        Visualize detections.\n",
    "\n",
    "        Args:\n",
    "            img ([type]): RGB image\n",
    "            data ([type]): points detected\n",
    "\n",
    "        Returns:\n",
    "            [type]: RGB image with detections\n",
    "        '''\n",
    "        limg = img.copy()\n",
    "        for v in data:\n",
    "            cv2.circle(limg, (v[0], v[1]), 2, [255], -1)\n",
    "\n",
    "        return limg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolatore dei punti individuati\n",
    "\n",
    "*Interpolator* è una classe che permette di ottenere le linee che meglio approssimano quelle della strada, partendo dai punti rilevati.\n",
    "\n",
    "Metodi:\n",
    "\n",
    "- **interpolate**: esegue l'interpolazione polinomiale sui punti di una corsia rilevata, seleziona il miglior grado del polinomio se richiesto, calcola i valori interpolati e restituisce le coordinate interpolate.\n",
    "\n",
    "- **echidistant_lane**: genera l'altra linea della corsia data la linea identificata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interpolator():\n",
    "\n",
    "    def __init__(self, max_poly_degree=3):\n",
    "        '''\n",
    "        Initialize the Interpolator object.\n",
    "\n",
    "        Args:\n",
    "            max_poly_degree: the maximum polynomial degree\n",
    "        '''\n",
    "        self.max_poly_degree = max_poly_degree\n",
    "\n",
    "    def interpolate(self, pts=dict(), ip_params={'start': 0, 'stop': 240, 'steps': 20}, key='mid', equ_selector=False):\n",
    "        '''\n",
    "        Takes detected points, find the corresponding polynom that fits the data.\n",
    "\n",
    "        Args:\n",
    "            pts ([type], optional): detected points. Defaults to dict().\n",
    "            ip_params (dict, optional): interpolation info. Defaults to {'start': 0, 'stop': 240, 'steps': 20}.\n",
    "            key (str, optional): Name of the line. Defaults to 'mid'.\n",
    "            equ_selector (bool, optional): search the best fitting equation (line / curve, etc.). Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            [type]: interpolated points\n",
    "        '''\n",
    "        data = np.array(pts[0][key])\n",
    "\n",
    "        x_coord = data[:,0]\n",
    "        y_coord = data[:,1]\n",
    "\n",
    "        min_mse_pos = self.max_poly_degree\n",
    "\n",
    "        # polynomial degree selector\n",
    "        if equ_selector == True:\n",
    "            # find the best fit\n",
    "            best_poly = []\n",
    "            best_fit = []\n",
    "            for i in range(0, self.max_poly_degree):\n",
    "                pfit = np.polyfit(y_coord, x_coord,i)\n",
    "                polynom = np.poly1d(pfit)\n",
    "                test_y = polynom(x_coord)\n",
    "                difference = y_coord - test_y\n",
    "                st_d = np.std(difference)\n",
    "                best_poly.append(st_d)\n",
    "                best_fit.append((pfit, polynom))\n",
    "\n",
    "            # select best polynom\n",
    "            min_mse_pos = np.argmin(np.array(best_poly))\n",
    "\n",
    "        # order start from 1, position from 0\n",
    "        pfit = np.polyfit(y_coord, x_coord, min_mse_pos)\n",
    "        polynom = np.poly1d(pfit)\n",
    "\n",
    "        y_ipp = np.float32(np.linspace(ip_params['start'],ip_params['stop'],ip_params['steps']))\n",
    "        x_ipp = polynom(y_ipp)\n",
    "\n",
    "        ply_coords = np.column_stack((x_ipp,y_ipp))\n",
    "        return {key:ply_coords}\n",
    "\n",
    "    def echidistant_lane(self, warper: ImageWarp, lane_pts, init_dist=115, final_dist=250, lane_side=1):\n",
    "        '''\n",
    "        Create echidistant lane based on the input lane points, considering the deformation generated by the prospective of the camera.\n",
    "\n",
    "        Args:\n",
    "            warper: ImageWarp object\n",
    "            lane_pts: points belonging to the lane detected\n",
    "            init_dist: initial distance (width of the roadway at the most distant point from the camera)\n",
    "            final_dist: final distance (width of the roadway at the closest point to the camera)\n",
    "            lane_side: if it is equal to 1, the lane detected is the right one, if it is equal to -1, the lane detected is the left one\n",
    "\n",
    "        Returns:\n",
    "            echidistant generated lane points\n",
    "        '''\n",
    "        buffer = []\n",
    "        dist = init_dist\n",
    "        dist = proportional_spaced_array(lane_pts[0][:, 1], init_dist, final_dist)\n",
    "        # create the lane points echidistant to the passed points\n",
    "        for i in range(0, len(lane_pts[0])):\n",
    "            x = lane_pts[0][i][0]\n",
    "            y = lane_pts[0][i][1]\n",
    "\n",
    "            nx = x\n",
    "            nx = nx - dist[i] * lane_side\n",
    "\n",
    "            norm_pts = np.float32(np.column_stack((nx, y)))\n",
    "            buffer.append(norm_pts)\n",
    "\n",
    "        buffer = np.array(buffer, dtype=np.float32)\n",
    "        buffer = cv2.perspectiveTransform(buffer, warper.warp_mat)\n",
    "\n",
    "        return np.array(buffer, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settaggi per il processing\n",
    "\n",
    "- *src* e *dst* rappresentano l'associazione dei punti dell'immagine di partenza con quelli dell'immagine deformata (es: il punto con coordinate (70, 240) corrisponderà al punto (155, 270) nell'immagine trasformata, in modo analogo gli altri punti)\n",
    "- *scan_range* indica il range verticale nel quale verranno valutati i punti delle linee e il salto da fare per ogni valutazione\n",
    "- *scan_window* rappresenta la finestra nella quale viene cercato un punto appartenente ad una linea\n",
    "- *offset* indica l'offset verticale\n",
    "- *image_width* contiene la larghezza dell'immagine\n",
    "- *lanes* rappresenta le aree nelle quali vengono valutate le linee della carreggiata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src = [[70, 240], [430, 240], [0, 0], [500, 0]]\n",
    "dst = [[155, 270], [165, 270], [0, 0], [320, 0]]\n",
    "\n",
    "scan_range = {'start': 0, 'stop': 240, 'steps': 10}\n",
    "scan_window = {'height': 8, 'max_adjust': 8}\n",
    "offset = 150\n",
    "image_width = 500\n",
    "\n",
    "lanes = [\n",
    "    {'label': 'mid', 'detections': {'start': {'x': 120, 'y': 230}, 'stop': {'x': 160, 'y': 230}}},\n",
    "    {'label': 'right', 'detections': {'start': {'x': 160, 'y': 230}, 'stop': {'x': 200, 'y': 230}}}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Istanziamento degli oggetti per il processing dell'immagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "warper = ImageWarp(img_width=image_width, offset=offset, src=src, dst=dst)\n",
    "detector = Detector(scan_range=scan_range, scan_window=scan_window)\n",
    "interpolator = Interpolator(max_poly_degree=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzione di processing dell'immagine\n",
    "\n",
    "Questa funzione rileva le linee di corsia in un'immagine, le interpola per ottenere curve lisce, le trasforma alla prospettiva originale e salva i risultati in una coda, per la visualizzazione.\n",
    "\n",
    "La linea rilevata viene mostrata in **blu**, mentre la linea generata a partire da quella rilevata viene disegnata in **verde**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, res):\n",
    "    '''\n",
    "    Process the input image, detect lanes, interpolate and draw the echidistant lane.\n",
    "\n",
    "    Args:\n",
    "        image: the input image\n",
    "        res: the queue to put the result\n",
    "    '''\n",
    "    try:\n",
    "        img = image.copy()\n",
    "        f_img = detector.img_filter(img)\n",
    "        f_w_img = warper.img_warp(f_img, offset=True)\n",
    "\n",
    "        color = [1, 1, 1]\n",
    "\n",
    "        # img_detected_points = f_w_img.copy()\n",
    "        debug = f_w_img.copy()\n",
    "\n",
    "        # detect lanes points\n",
    "        detected_points = {}\n",
    "        for i, lane in enumerate(lanes):\n",
    "            detected_points[lane['label']] = detector.get_lane_detections(f_w_img, start=lane['detections']['start'], stop=lane['detections']['stop'], use_RANSAC=True)\n",
    "\n",
    "            # draw detection area\n",
    "            start_x = lane['detections']['start']['x']\n",
    "            start_y = lane['detections']['start']['y']\n",
    "            stop_x = lane['detections']['stop']['x']\n",
    "            stop_y = lane['detections']['stop']['y']\n",
    "            cv2.rectangle(debug, (start_x, start_y), (stop_x, stop_y), (255, 255, 255), 2)\n",
    "\n",
    "        # select the best lane (the one with the most detected points)\n",
    "        lane = None\n",
    "        if detected_points['mid'].shape[0] > detected_points['right'].shape[0]:\n",
    "            lane = lanes[0]\n",
    "        else:\n",
    "            lane = lanes[1]\n",
    "\n",
    "        # img_detected_points = detector.draw_detections(img_detected_points, detected_points[lane['label']])\n",
    "\n",
    "        # interpolate the lane points\n",
    "        interpolated_points = interpolator.interpolate([detected_points], key=lane['label'], equ_selector=False)\n",
    "\n",
    "        pts = np.array([interpolated_points[lane['label']]])\n",
    "        cv2.polylines(debug, [np.int32(pts)], False, [155], 2)\n",
    "\n",
    "        # unwarp the lane points\n",
    "        unwarped_pts = np.int32(warper.pts_unwarp(pts))\n",
    "        unwarped_pts_offset = np.add(unwarped_pts, [0, offset])\n",
    "\n",
    "        color[0] = 255\n",
    "        cv2.polylines(img, [unwarped_pts_offset], False, color, 2)\n",
    "\n",
    "        # estimate the echidistant lane\n",
    "        ed_pts = np.float32(interpolator.echidistant_lane(warper=warper, lane_pts=unwarped_pts, lane_side=1 if lane['label'] == 'right' else -1))\n",
    "        cv2.polylines(debug, [np.int32(ed_pts)], False, [155], 2)\n",
    "\n",
    "        # unwarp the echidistant lane points\n",
    "        ed_unwarped_pts = np.int32(warper.pts_unwarp(ed_pts))\n",
    "        ed_unwarped_pts_offset = np.add(ed_unwarped_pts, [0, offset])\n",
    "\n",
    "        color[0] = 1\n",
    "        color[1] = 255\n",
    "        cv2.polylines(img, [ed_unwarped_pts_offset], False, color, 2)\n",
    "\n",
    "        # draw the separation for the lanes\n",
    "        middle = lanes[0]['detections']['stop']['x']\n",
    "        cv2.rectangle(debug, (middle, lane['detections']['start']['y'] - 10), (middle, lane['detections']['start']['y'] + 10), (255, 255, 255), 2)\n",
    "        concat_img = cv2.hconcat([img, cv2.cvtColor(debug[:, :dst[3][0]], cv2.COLOR_GRAY2RGB)])\n",
    "\n",
    "        res.put(concat_img)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        start_x = lane['detections']['start']['x']\n",
    "        start_y = lane['detections']['start']['y']\n",
    "        stop_x = lane['detections']['stop']['x']\n",
    "        stop_y = lane['detections']['stop']['y']\n",
    "        cv2.rectangle(f_w_img, (start_x, start_y), (stop_x, stop_y), (255, 255, 255), 2)\n",
    "        concat_img = cv2.hconcat([image, cv2.cvtColor(f_w_img[:, :dst[3][0]], cv2.COLOR_GRAY2RGB)])\n",
    "\n",
    "        res.put(concat_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definizione valori di dimensione\n",
    "\n",
    "- *camera_width* e *camera_height* sono le dimensioni dell'immagine catturata dalla camera\n",
    "- *crop_width*, *crop_height* e *height_adjust* sono i valori della porzione di immagine da analizzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_width = 800\n",
    "camera_height = 600\n",
    "\n",
    "crop_width = 500\n",
    "crop_height = 240\n",
    "height_adjust = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esecuzione del programma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: listening to server 127.0.0.1:2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to CARLA manual control.\n",
      "\n",
      "Use ARROWS or WASD keys for control.\n",
      "\n",
      "    W            : throttle\n",
      "    S            : brake\n",
      "    A/D          : steer left/right\n",
      "    Q            : toggle reverse\n",
      "    Space        : hand-brake\n",
      "\n",
      "    L            : toggle next light type\n",
      "    Z/X          : toggle right/left blinker\n",
      "\n",
      "    TAB          : change sensor position\n",
      "    ` or N       : next sensor\n",
      "    [1-9]        : change to sensor [1-9]\n",
      "    C            : change weather (Shift+C reverse)\n",
      "\n",
      "    F1           : toggle HUD\n",
      "    ESC          : quit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remove_all(world)\n",
    "\n",
    "processed_output = Queue()\n",
    "\n",
    "# setup the simulation environment\n",
    "game_loop = manual_control.setup()\n",
    "\n",
    "# get the vehicle and attach the camera\n",
    "vehicle = world.get_actors().filter('vehicle.*')[0]\n",
    "front_camera = spawn_camera(attach_to=vehicle, transform=carla.Transform(\n",
    "        carla.Location(x=0.3, y=0.0, z=1.5), # posizione dello specchietto retrovisore\n",
    "        carla.Rotation(pitch=-10.0)\n",
    "    ),\n",
    "    sensor_tick=0.1,\n",
    "    width=camera_width, height=camera_height\n",
    ")\n",
    "\n",
    "cv2.namedWindow('Processed', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# callback for the camera\n",
    "def camera_callback(image):\n",
    "    '''\n",
    "    Callback for the camera.\n",
    "\n",
    "    Args:\n",
    "        image: the image captured by the camera\n",
    "    '''\n",
    "    try:\n",
    "        video_output = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "        video_output = video_output[:, :, :3]\n",
    "\n",
    "        # Crop the image (zoom)\n",
    "        start_x = (video_output.shape[1] - crop_width) // 2\n",
    "        start_y = (video_output.shape[0] - crop_height) // 2 - height_adjust\n",
    "        cropped_img = video_output[start_y:start_y + crop_height, start_x:start_x + crop_width]\n",
    "\n",
    "        # process the image in a separate thread\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            executor.submit(lambda: process_image(cropped_img, processed_output))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e.with_traceback())\n",
    "\n",
    "# attach the callback to the camera\n",
    "front_camera.listen(lambda image: camera_callback(image))\n",
    "\n",
    "# start the game loop\n",
    "try:\n",
    "    game_loop.start(processed_output, autopilot=True)\n",
    "except KeyboardInterrupt:\n",
    "    cv2.destroyAllWindows()\n",
    "finally:\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
